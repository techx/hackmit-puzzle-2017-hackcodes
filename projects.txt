falltrack about one third of the elder population over the age of falls each year and the risk of falls increases proportionately with age but these statistics fall short of the actual numbers since many incidents are unreported by seniors and unrecognized by their caregivers falls are the leading cause of death due to injury among the elderly of all fractures in the elderly are due to falls falls account for of all hospital admissions and of all nursing home admissions of those admitted do not return to independent living die within a year falltrack helps to solve this problem and take a better care of your elderly loved onesfalltrack accurately detects when the person falls using accelerometer its algorithm helps to distinguish falls from other physically similar activities we built it using arduino and ios app we had problems with the microcontroller and had to fix false positives due to lack of some equipments we had to improvise with what was available at the time we are proud of building a fully functioning wearable from the scratch we learned to debug the hardware and utilize available resourceswhats next for falltrackwe hope falltrack can help to reduce the fall rate among elderly population in the future
did duke baseball win my brother plays baseball for duke the website diddukewincom shows the results of the latest duke basketball game but there is no such site for baseballit returns w l c or p depending on whether the game was won lost cancelled or postponedwhats next for did duke baseball winwe hope to soon deploy did duke baseball win on a website and host it on heroku
 whats next for rohbot
awechordswebsite a club ive been involved in since freshman year needed to revamp their sitenew website htmlcss bootstrap challengesbugsstill in process of fixing header image cutoff menu issues when resizing pageconverting sketchadobe xd prototype into a working site using bootstrap framework whats next for awechordswebsiteadding toggle function for alumni and current members
pusheen sell we wanted to create a fun and easy way for students to sell items on campuspusheen sell allows users to browse items currently for sale and sell items of their own not only is the app quick and easy to use but it also gives more information about the items on sale through short videosthe app is built using xcode and swift and the backend is handled via firebasewe started out with a much more ambitious project than we could complete in hours so we had to make some hard decisions and cut features in order to make a working appwere happy that we were able to get the video processing workingproper git management is important even with a small team in the same placewhats next for pusheen sellwe would like to add a few more features that we couldnt complete in hours and eventually get the app in hands of students to start user testing eventually this would be a great app to be used on campuses across the world
cakeboxbot instructionsis it your birthday is it your years anniversary today you need a cake but how cakebox is here for you sit tight and message facebookcomcakeboxbot with i want a cake for name type your address then choose the cake you want and confirm with ok or exit the chat and make cakeboxbot sad once your order is confirmed postmates and pusheen maybe will deliver the cake to you from the closest bakery to your location all transactions are done in cash note that you have to authorize the cakebox app before you can send it messagescakeboxbot is a messenger bot that will order you a cake ondemand instantly by calling the postmates api on our own server with the encouragement of pusheen and xkcdwe wanted to experiment with messaging bots since they are a popular emerging technology we built cakeboxbot with nodejs hosted it on heroku and we picked facebook as our bot platformunderstanding how to connect the front and back ends of our application took the most time but we realized that we didnt actually need to add that much to our frontend if we used facebook messenger which is espusheenly greatcake cake caketeamwork and bots are hard and fun and cakewhats next for cakeboxbotcupcakes
u succ many people think succulents are cute and harmless theres even a whole game you can play devoted to therapeutically taking care of themthis succulent is different thoughu succ generates a mean plantrelated insult at you when you click on the succulent html css javascriptjquery shakejs for animation photoshop for asset illustrationuh i think it breaks if you click really fast something something javascript event timing whateveri think i conveyed the emotionality of the anger well through color and animationnot all technology is good im no herowhats next for u succmaybe a real dynamic app thats social grow ur own succulent and send insults to your friends gain social capital by putting others down quite a representation of the real world
analytics for cities analytics for citiessee notebook here httpsgistgithubcomrasmiaebbbcedcfce
fretless learning a new instrument is hard inspired by games like guitar hero we wanted to make a fun interactive music experience but also have it translate to actually learning a new instrument we chose the violin because most of our team members had never touched a violin prior to this hackathon learning the violin is also particularly difficult because there are no frets such as those on a guitar to help guide finger placement fretless is a modular attachment that can be placed onto any instrument users can upload any midi file through our gui the file is converted to music numbers and sent to the arduino which then lights up leds at locations corresponding to where the user needs to press down on the stringfretless is composed to software and hardware componentswe used a python midi library to convert midi files into music numbers readable by the arduino then we wrote an arduino script to match the music numbers to the corresponding light because we were limited by the space on the violin board we could not put four rows of leds one for each string thus we implemented logic to color code the lights to indicate which string to press one of the challenges we faced is that only one member on our team knew how to play the violin thus the rest of the team was essentially learning how to play the violin and coding the functionalities and configuring the electronics of fretless at the same time another challenge we ran into was the lack of hardware available in particular we werent able to check out as many leds as we needed we also needed some components like a female dc power adapter that were not present at the hardware booth and so we had limited resources and had to make do with what we had were really happy that we were able to create a working prototype together as a team some of the members on the team are also really proud of the fact that they are now able to play ode to joy on the violindo not crimp lights too hardthings are always harder than they seem to beode to joy on the violin whats next for fretlesswe can make the leds smaller and less intrusive on the violin ideally a led pad that covers the entire fingerboard also we would like to expand the software to include more instruments such as cello bass guitar and pipa finally we would like to corporate a pdf sheet music to midi file converter so that people can learn to play a wider range of songs
political personality quiz moral machine mits online selfdriving car moral choice quiz inspired us to make our own version to predict ones personality based off presidential databased on certain data scraped from wikipedia and other sources about the upcoming election we chose certain traits randomly to learn about the users personality we aggregate the submission data and compare your responses to the average of other test takers which will tell you at the end which candidate you actually align with based off nonpolitical questionswe wrote a simple but interesting web app using htmlcss and javascript and hosted it on herokuplenty of interesting facts about our upcoming presidential candidateswhats next for personality quizwe can use this data to predict how people can influence certain swing states and were also interested in using beaker to further provide a cleaner and deeper analysis going even further we could possibly interface this web app with the muse headband to track brain data for each of the questions and compare between users as well as use machine learning to learn from the aggregated user data and attempt to predict what one would choose for each question
remember the cat the game simon was the inspirationyou memorize a sequence all at once and recreate it with catsmit app inventormaking a delay function workfinishing a projectwhats next for remember the catscrolling trhougih different memes when you press the reset buttonlinkaiappinventormitedugalleryid
just write fight writers block with motivation from your favorite internet friends every characters a new image of a baby animal parsed from google images will appear across your screen
stemlabs top at hackmit all of us have struggled to some degree with firstandsecond year stem courses in university we were frustrated by the lack of tools and support out there to help university students visualize and understand complex topics such as search algorithms multivariable calculus and physics so we thought itd be cool to see how we could hack that problem using microsoft hololensthe user can use microsoft hololens gesture controls to select hisher desired tutorials and then could see a visualization of difficult concepts we are currently starting out with the visualization of dfs algorithmwe built it in unity visual studiothree people on our team have no prior experience working with hololens or unity the other teammate also only has limited knowledge in unity we essentially all started from point zero and tried to learn how to make a working hololens app demo within a weekendaccomplishments that we are proud ofwe are quite proud of our learning curve progress we did our best to learn and code as much as we canunity hololens basicswhats next for stemlabsinteractivity and an overall immersive experience are the two main pillars the idea took off with and we are definitely planning to work on this app in the future to improve these two aspects we also want to enable ocr so that the user could view d graphs by simply highlighting an area that heshe does not understand more things to come include voice commands and nlp algorithms to make the app smarter we are all really excited to explore the possibilities of how ar could change the way we learn and we are planning to continue diving deeper into ar dev after this hackathon
autocensor realtime news reporting is almost hereif only there was realtime censoring technologyfeed in an audio file with cuss words outputs the audio file with the cuss words silenced in real timein java we translated speech to text using ibm watsons speechtotext function then silenced the parts of the audio corresponding to the blacklisted wordstereo audio doesnt work with the audio readerwriterwe worked with things that we werent familiar with ibm watson and this is the first software hack for one of our memberswe learned how to work with git maven http ibm watson audio processingwhats next for autocensorwe are trying to autocensor songs and allow compatibility with other audio formats and even video
museic it generates piano music that is learned from popular edm musicwe used python to preprocess the data to turn it into a feature vector of frequencies and amplitudesassembling the music back after we stripped it to its basicswe successfully converted many tracks into a midilike format so we have a larger databaseto train music from
predictosaurus as clueless college freshmen navigating the labyrinth of classes with cryptic names and descriptions we felt that it would be extremely helpful to know which classes we would like before taking them mit and harvard both already maintain a course evaluations database but they only provide generic information describing the central characteristics of the student population whereas students perceptions of these classes vary wildly based on a number of intrinsic factorsthe program learns the preferences and abilities of each student while simultaneously learning how these characteristics affect how students perceive the classes they are taking it predicts how students would rate classes before they take them and can be used as a guide for selecting interesting classes while balancing the weekly workloadthe backend is a python tcp server that uses collaborative filtering to learn both students characteristics and the function mapping characteristics to predict ratings it differentiates the matrix expression describing this relation and performs gradient descent to minimize the mean squared error between the predicted ratings and the sparse set of known ratings provided by student responsesthe front end is a static html website it uses javascripts websocket api to connect to websocketd which opens a netcat process to route packets to the tcp port that the python backend is listening on whats next for predictosaurusthe next step would be to obtain public hosting for the python backend so that predictosaurus would be accessible to the wider mit and harvard community as a machine learning application it becomes more effective and generates more accurate results as more students submit their ratings to the database so it is important that it is adopted by as many students as possible
split scan splitme
ethereum piggy ethereum piggy lets you save money with a virtual piggy bank the app connects to your coinbase ethereum wallet and allows you to put money into your virtual piggy bank thanks to ethereums contracts in the blockchain we secure the savings until a set time and can guarantee that they will be released after the time to the original owner
art we wanted to play with a kinectplays notes on a pentatonic scale based on the joint movingmodifying the kinect demolearning clearning ccwhats next for artlearning c properly and expanding on the capabilities of merging algorithmic music generation with movement
tinderprint tinderprinttinderprint is a dating app that matches you with people basedon true physical and spiritual compatibility for milleniahandreaders have been using fingerprints to characterize peoplespersonalities and to predict major life events tinderprint usesa neural net to analyze the unique qualities of your fingerprintwe use these qualities to match you with people with compatiblepersonalities helping you get to your next major life event tinderprint uses a convolutional neural network trained on a public data set to identify the prominent features of your fingerprint according to thousands of years of fingerprint reading the presence of loops reveals your intelligence and demeanor the presence of whorls indicates your will and conviction and the presence of arches exposes your pragmatism and stubbornness we use a similarity metric across these features and more to help you find partners youll be compatible withrunning the appto run an instance of tinderprint download the latest versions of npmand mongo run mongo in the background on port install theapps dependencies and run the app you can then access the app atlocalhostmongod npm installnpm start
fidgetwidget fidgetwidgeta hardware hack designed to allow a safe interactive stimming experience for both autistic and allistic individualscreated at hackmit by kathleen burkhardt and jeremy hongwhat is stimmingaccording to wikipediaselfstimulatory behavior also known as stimming and selfstimulation is the repetition of physical movements sounds or repetitive movement of objects common in individuals with developmental disabilities but most prevalent in people with autistic spectrum disorders it is considered a way in which autistic people calm and stimulate themselves therapists view this behavior as a protective response to being overly sensitive to stimuli with which the individual blocks less predictable environmental stimuli sensory processing disorder is also given as a reason by some therapists for the condition another theory is that stimming is a way to relieve anxiety and other emotionsthis project was built to show that stimming is a natural and calming experiencesetupto set up your own fidgetwidget you will needbreadboard buttons k ohm resistorsphotoresistorpotentiometerjumper wiresarduino microraspberry piraspberry pi monitorsee the circuit schematic for details on how to assemble the circuitonce the circuit is assembled run the code on the arduino and the raspberry pi
flyout go prepared as people who travel often either for leisure or for business planning a trip each time is a hassle finding flights finding places to visit and knowing the weather condition there requires efforts of research for example i forgot to bring warmer clothes to boston we put these elements together to create flyout a webapp that finds you the cheapest flight local attractions and weather tipsflyout is a webapp that finds you the cheapest flight local attractions and weather tipsthe entire platforms frontend is built on html css and bootstrap backend was built using javascript and jquery amadeus api was utilizedcoming up with an idea was the hardest part coming into the hackathon not knowing what to build we thought of how much travel has been part of our lives we travel to go to hackathons go meet friends for work and to have fun we wanted to make planning for these a bit easier for our userswere proud that we were able to finish brainstorming and building a product that works within hours this is my first hour hackathon and it was definitely a challenge to do everything that we wanted to dowe learned that its really hard to think of new ideas that relate to travel whats next for flyout go preparedwe are hoping to incorporate more apis to optimize our users travel experiences we hope to incorporate facebook authentication to retrieve mutual friends living in the area and grab public facebook events that are happening in the users destination
webb after using d for a summer position i stumbled upon a forcedriven graph of nodes and edges that moved as you dragged a vertex and adjusted accordingly i seriously wondered what sort of data could possibly be visualized this way after viewing another weblike visualization of data i imagined the same type of graphical representation of a facebook account sign in with your facebook account and webb will load your recent pictures and posts adding them as nodes connected to me on a forcedriven graph users who engage with you posts likes comments tags are also added to the graph connected to each respective piece of media with which they engaged this gives a completely new view of your social interactions and using the forcedriven graph you can tug on nodes and see which ones are most connected to you and your social webfacebook api nodejs and djsfacebook api permissions converting raw facebook data to a valid set of vertices and edges creating a fluid and interestingly unique designprinciples of djs and the facebook apiwhats next for webbmore filtering options and better graphical visualizations of nodesnotethe navigating to the heroku link httpsshelteredreefherokuappcom currently only works for facebook profiles added as testers for webb retrieving some permissions requires approval that we didnt have time for during hackmit but are applying to after
auto biometrics to expand the scope of automotive biometricsour project aims to increase the scope of vehicle biometrics by automatically adjusting the vehicles seat temperature and radio when the driver scans their fingerprint to turn on their car we used synaptics fingerprint scanning hardware to scan the users fingerprint and compare it with authorized driver profiles stored in the systemaccurate fingerprint recognitionwe didnt use a finger recognition api or librarywe learned about high resolution capacitive sensing and fingerprint recognition algorithms whats next for auto biometricsupdate the gui and interface with actual vehicles
icrs checkout we needed a system to operate our hackspace utilities shop where we sell materials snacks and even the use of some restricted equipment it needed to be instantaneous allow for a small amount of debt in case of emergency and work using our college id cards to keep track of who is purchasing whateach student has a set credit assigned to them that they may spend in our shops products to start the transaction they must tap their college id onto the rfid scanner and after being able to check their current credit they can scan the barcode of the product they want to buy if this transaction would leave them with less than of debt the may scan more items or proceed to checkout their credit can be topped up through our college union website which will in turn update our database with their new credit amountthe interface is built in bootstrapgenerated webpages html that we controlled with python and these are locally hostedwe hosted all of our databases on firebase accessing them through the firebase api with a python wrapperconnecting the database with the gui without the python program crashing took the majority of our debugging time but getting it to work in the end was one of the most incredible moments of the weekendweve never made a webapp before and we have been pleasantly surprised with how well it turned out it was clean easy to use and modular making it easy to update and developinstead of using technology we wouldnt have available back in london and doing a project with no real future outlook or development we chose to tackle a problem which we actually needed to solve and whose solution we will be able to use many times in the future this has meant that competing the hackathon will have a real impact in the every day transactions that happen in our labwere also very proud of developing the database in a system which we knew nothing about at the beginning of this event firebase it was challenging but the final result was as great as we expectedduring the hackathon we have improved our coding skills teamworking database management gui development and many other skills which we will be also able to use in our future projects and careerswhats next for icrs checkoutbecause we have concentrated on a specific range of useful tasks for this hackathon we would love to be able to develop a more general system that can be used by different societies universities and even schools operated under the same principles but with a wider range of card identification possibilities products and debt allowance
whiptrip visit httpwwwwhiptripco to try out app desktop onlymost travel search engines prompt you for too much like travel dates and specific destinations for the single college traveler or the millennial the opportunities to travel are limited mostly by budget constraints we designed whiptrip to quickly determine some of the best possible trips within any budget regardless of time or destinationtechnologies usedwe used nodejs for the backend and basic javascriptjquery for the frontendwe also used the amadeus apis for travel itineraries the foursquare api for things to do and the api for image infocombining flights and hotelsin order to achieve a set of trips within a budget one must account fo the combination of flights and hotel there is potential for a cheap flight combined with an expensive hotel an expensive flight combined with a cheap hotel or any range in between thus we used the amadeus apis to quickly generate broad searches for both flights and hotels and used a custom algorithm to combine themwhats next for whiptripwed like to connect to affiliate links with the major travel providers and provide this service for more than just trip ideas wed like to have the ability to book straight through whiptrip also we would like to tie in optional car rental and public transit costs as well as cost of living based on the budgetyourtravelcom api
driverfy it is cool
controlgeek the era of controlling your devices from anywhere in the world is here and we want to include everyone in the exciting new developmentsusing easy hand gestures you can wirelessly control electronic devices from anywhere in your hometo create our product we programmed the touch pad and wireless transmitter in python and the receiving end a raspberry pi in python with an interface written in javascriptthe touchpad drivers were difficult to install and the values it reported varied significantly as a workaround to this issue we created a baseline value for each pixel on the touchpad and enumerated the values that varied greatly from their baseline indicating a touchas we had to run our raspberry pi headless due to a lack of monitor we initially needed to hunt down the pis ssh server on the open hackathon network eventually we were able to setup a linklocal connection for some initial configuration and transfer that to the open network after the pi was setup we encountered an issue with our servos behaving erratically it turned out that the python gpio library that came with the pi did not allow for enough precision to give us any sort of fine grained control over the servos switching out the library for one built out of c solved the problemthere were two really defining moments of this hack the first was when our web interface on the raspberry pi first gained full control of our servos and lights allowing us to eventually expose an interface to the touchpaddriving code the second defining moment was when we finally fixed all the major bugs in the touchpaddriving code allowing it to properly detect gestures for the first timewe learned a lot about python signal processing techniques analog servo operation and a whole host of bits of knowledge in our building of controlgeek both from each other and from the great mentors hackmit had around we cant count how many times we called over someone from the synaptics boothwhats next for controlgeekthe next step for controlgeek would first include extending gesture support to detect different numbers of fingers varying speed and slow tracking from there controlgeek could be hooked into any number of functionalities of a home such as lights blinds fans and media players
smart property in a world where people are getting more and more connected due to the iot technologies people in developing countries find the cost of just joining the conversation prohibitive however when combining iot technologies and a more mobile money solution it becomes possible to enable certain business models as well as financial services to these people still companies like mkopa that follow a sort of similar pay as you go model find it hard to keep up with operating costs so this is a an exploration of a more grass roots approach the demonstration is for a theoretical display that can be used to advertise people are free to rent display time and the money is distributed fairly through the use of a smart contract to the investors i had been working on the smart contract as an open source project for a while and i decided it could be cool to polish it more and show it to people were that i didnt have enough time to do an owner display to show the money distributing towards investors but it is still possible to see that the system does workaccomplishment is that i mainly worked on this by myself and i think it is still a pretty good demonstration despite the limited time i had i learned it isnt such a great idea to start at the halfway point of the hackathon and miss out on all the cool hardwarewhats next for smart property remains to be seen
seeingeye we wanted to build a service for the hard of hearing and visually impaired that enabled them to experience the world around them utilizes android and hololens to create a more sensational experience gathering video and audio to explain and caption the world around the user
scylla privacy on the web has become a leading issue amongst politicians tech companies and even average consumers recently the rise in concerns with who is monitoring communications or selling potentially sensitive information to whom forces many compromises in security our initial plan was to build an anonymizing network layer that could encrypt a users traffic without the need of a specific browser or introducing highly limiting connection speeds after considerable development however we decided to narrow our focus to a highly protected chat client using the same cryptography engine but without an interface to the network protocols that gave us issuesit allows two users to engage in a conversation over a peer to peer network that is virtually uncrackable rsa encrypted salts for aes keys that expire within minutes allowing for an anonymized interactionall built in java utilizing kryonet and crypto librariesas neither of us came into this hackathon with much network experience setting out to build a viable alternative to tor and ip was a tad overambitious we were using a custom built socks proxy that could intercept and manipulate raw packets but we ran into unforeseen issues in the systematic deletion of clients before they could be used to return network data we suspect that some operating system kernel trickery was to blame for this but due to having not much time to debug this was not confirmedwe have built a solid foundation for the project we originally set out to make so with continued development and a lot of traffic to stackoverflow we can reach our initial goal all of the logic still holds and the fact that at am after having dealt with socks issues for the last few hours we were able to narrow our scope and create a working product is an achievement in and of itself by showing practical use of our product already in place we can continue to build upon what we created here without getting heavily invested only to find it is not feasiblewe learned quite a lot about how java handles sockets and the balance between a usable ie not mind numbingly slow constantly timing out system and a completely secure onewhats next for scyllaa movement towards universal compatbility at either a socks proxy level or httpssl proxy level would be explored again for sure that would make the system far more accessible to average users and allow for organic growth in the size of the network
webscrapingwikipedia it utilizes d and displays the page views for candidates clinton and trump wouldve been nice to add bernie and cruzi dont have a domain for hostingsameorigin policy issuesi did itmore about d and pandaswhats next for webscrapingwikipediacontinue exploring wikipedia apis theyre pretty neat
homebites university students often skip out on meals or pursue food only when its free for these students dinner has become an unavoidable expenditure instead of an enjoyable tasty experience with homebites students can conveniently experience the joys of a warmly cooked meals with interesting company homebites connects guests to local hostsresidents who are willing to make a homecooked meal in addition given the commitment of preparing meals homebites has a catering option for hosts who have extra food ensuring that hosts do not lose money whatsoever this is ideally suited for university students who want a homecooked meal as well as travelers who wish to taste authentic local food in a region homebites was built with microsoft azure facebook messenger and graph api capital one api postmates api and apiaiazures machine learning studio has problem reading azures documentdb source in addition communication between the messenger chatbot and the azure database often needs to be debugged the fact that facebook messengers payment method requires several days for facebook to be approved means we need to seek alternative payment approaches and neither capital one nor coinbase the available payment apis are mainstream enough to reach a wide audience the chatbot has a good user interface and is extremely convenient to usewe became more familiar with the graph and messenger api in facebook and microsoft azure whats next for homebiteshomebites is ready to launch as soon as scalability issues are addressed
vral vralthis is supposed to detect coughing sounds in lecture recording but were not finished with it yetbut for now at least you can run in terminal python rosatensorflowpy name of a audio fileand it should give you a pretty visualization of your audio file make sure you have numpy and librosa installednext time hopefully we can use tensorflow to make this much betterif youre using virtual environment in pythonhttpsvirtualenvpypaioenstablevirtualenv venvsource venvbinactivatepip install r requirementstxtthanks hackmit
encoreai encoreaigenerate new lyrics in the style of any artist using deep learning try it out at httpencoreaimusic lives foreverfrom elvis to the beatles nirvana to tupac many of the artists we love are no longer creating encoreai lets you revive the spirit of your favorite artists in the modern agewe are impatientcant wait for the next kanye album to drop were you part of the public outcry over the delayed release of frank oceans new record fret no more encoreai delivers your favorite artists next single at the touch of a buttonbut how does it workwe used tensorflow to create an lstm long short term memory neural network that reads all of the lyrics of any musical artist the network learns the style of how the artist writes the context of words rhymes linestanza breaks etc given a seed word or phrase it will generate a new song in that artists stylesome exampleskanye westnever i admit i cant do i see a drug som im bout to reunited ill need have to play me alone ill fade back o extra until they cover from an ultralight beam because you do her money before my sean harder now west i one awayim up so quit one yeah i will you see you need all your mic from a moment im saying violatelets got no goodbyes to a dem me now i been nothing funny but we go nget all my racks steps and rockin grandma watch my strippers got getting this b a shot is like somebody its old s and oh precious cause we call that ready for not hook its an room now in the restaurant clothing on standing dem my money kanye west lets fly off beats that im at these good life with you keep the big a take my things and throw my ss is strongertaylor swiftpaper lying here cause i swear out there aint where you outta be and you flashback to when he said forever and always oh and it rains in your bedroom everything is wrong it rains when the sun came up you were lookin at me santa baby forgot to mention one little thing a ringand i dont think it all through all these things will changecan you feel it now i fall in love with you give me a photograph to hang on my wall superstar howd we got problems and i dont think we can solve them you were the prince i used to see the one we danced to all night long cause you got me a nice new apartment in a city wouldnt you have to make me go back there again find the wrong wrong on our last night ooh ooh loves like this its something i missed ooh ooh ooh ooh it was the best night never would forget how he moved
recipe living off campus and no longer having a meal plan can be tough weve both always loved to experiment with new recipes but when you have to plan every meal you eat it can be overwhelming to build a grocery listif you are on a recipe page and the chrome extension is clicked a drop down menu appears with the ingredients mentioned in the recipe you can check any ingredients you need to buy and they are pushed to your grocery list the recipe url is sent to your planner where you can choose when you are eating these mealsfor the extension we had to parse the html of the page and find the ingredients and then use that to build an array of dictionaries of the amount unit and ingredient then that array is pushed to the server where it is saved to the list combining ingredients that are already seen in the list by adding the two amounts not every recipe website is the same were able to scrape from most major recipe websites but unfortunately the food blog websites could not be scraped by our original methodwhats next for recipeimproving aestheticsbuilding the weekly planner interface
smart drone delivery planning we wanted to build a very general multivehicle path planning simulator that boasted a unique user experienceallows users to specify within apple maps the location of any number of packages and their corresponding target destinations as well as any number of drones each of which can have a custom weight capacity once the locations are specified a path planning algorithm determines how to assign each of the drones to delivery tasks and a simulation is performedwe used a with an admissible heuristic initially to solve the path planning algorithm optimally but ultimately opted to use a more scalable algorithm at the cost of optimality that performs well in practiceeven with a as the number of packages increased beyond just a few the problem became quickly intractablethe algorithm that we designed scales easily with more drones and packages and still provides intelligent coordination between droneswe learned the high cost associated with optimal solutions when dealing with difficult optimization problemswhats next for smart drone delivery planningwe want to introduce constraints around the amount of time that a drone can stay in the air before it has to recharge
aisee this video is too long i want to navigate to the part where pusheen is like pikachudont we have ai to analyze videos and tell us that alreadyand thus the idea for aisee was bornwe found the clarifai api to help us out and now aisee can analyze youtube videos and tell you where certain components ie cats cute things etc appear in a video you can even visualize these components in terms of a graph its so convenient that its a chrome extension and you can view it with your open pusheen youtube video yay i can now click on a part of the timeline and find pusheens cutest moment
branch we were inspired by the current problems facing recipe websites if you look for a steak recipe sometimes the comments suggest edits that end up being even more popular than the original itself we want to use a tree structure to document the meaningful variations evolution of recipes and realized we could apply this technology to other problems as wellfor example when authors write stories their progression of ideas is anything but linear this infrastructure allows authors to more easily revisit older ideas and have any number of new ideas branch offit stores data in a nodelike format each node can have any number of children that stems from it in a branch like waywe used the express framework to develop a restful api that services our frontend and talks to firebase on the backendwe didnt know how to use firebase and express so this took a good chunk of timewe know now firebase and express wooofirebase expresswhats next for branchintegration with other services making it more generic
ultimate lights ultimate lightshackmit have you ever woken up in the morning in total darkness or with lights that are too brighthave you ever gotten up in the middle of the night to go to the bathroom only to fumble around for the light switchhave you ever been late leaving your home to an event despite all of the alarms that you set on your phoneultimate lights is here as a solution for all of those problems and morepicture your ceiling covered by a grid of led lights wouldnt it be great if those lights knew your schedule and where you were in the house at all times well wish no more we at ultimate lights have prototyped a unique software implementation of a smart led grid system that has the capability to follow you around the house by turning on the lights directly above you and in your path and turning off lights behind you the system can also be set to gradually turn on and off as you wake up and as you go to sleep and also has an alarm mode that causes the lights to flash continuously when you need to leave the house to get somewhereultimate lights has an easy to use user interface that allows users to set a schedule for their ultimate light system so that the system knows when to set off timing alarms and when the lights should follow you around the houseultimate lights utilizes an angularjs frontend framework in conjunction with a python backend a node web server and firebase to update our interface across machines in real time we also added a nativescript component to create native android and ios versions of our applicationthanks for taking the time to read our submission the ultimate lights team
camera calendar wanting to do something with computer vision reads images and tries to identify texti used tutorials created by google regarding ocr lots of difficulties with compatibility with python and the apis managed to get something dont use python untill apis show they can handle it whats next for camera calendaractual calendar support
silverback it was inspired by the surprising number of restaraunts that offer discounted food to college students near etsu there are many restaraunts that have slice nights draft nights or just for students most students on campus at etsu only know of maybe restaurants that offer these deals but there are so many more that students could be taking advantage ofit allows a restaurant ownermanager to login and post the deals that they offer these could be recurring deals such as student discounted rates or they could be a one time deal such as offering bogo sandwiches i went to the firebase workshop and learned about using firebase i sortve threw together a proofofconcept web app based on firebase tutorials and examplestesting the app was sometimes difficult while hosting it at localhost for some reason i then tried to upload to firebase but ran into more issuesim proud of getting a semiworking product readyi learned about the firebase tools that are availablewhats next for silverbacki plan to keep working on silverback and then start marketing it to restaurants that are around etsu ill probably come up with a more marketable name as well my vision for silverback would be to get it up and running then strongly urge restaurant owners to sign up and use the app for a year or so i hope to track the number of college students who go to the restaurant as a result of the app after demoing the application for a year or so i hope to sell it as a subscription marketing platform to local restaurants for example a restaurant may pay per year to be allowed to advertise on silverback
surpas pas stands for personal accountability system nthis project was inspired by a problem that one of our own organizations faced as a predominantly studentrun organization that had just begun last year we were searching for an rsvp and attendance system that we could use to expedite our accountability processes however despite long searches we could not find any products that seemed to perfectly fit our needs this is why we built surpas to help organizations like ours find a way to go above and beyond expectationssurpas is a web and mobileenabled application built for student leaders and members of a given organization to quickly and easily receive updates from their team leaders about events and requirements they will not only receive event notifications but they will also be able to quickly rsvp to events that they expect to attend as well then at mandatory events these students can gain credit for the hours they spent at the event by being verified by their small group leaders in addition to being able to quickly take attendance at meetings these small group leaders and their administrators may also pull up automatically generated reports about each individuals contributions and attendance records and if they so choose may be notified ahead of time if the student is on track to falling behind this way student leaders and administrators can quickly see where possible problem areas lie and they may resolve them before these situations worsen surpas is not only applicable to student organizations as its features can be very widely applicable to other programs from k extracurriculars to adult programs within the workplace nevertheless as students we found there was a huge gap in this market for student leaders and we hope that surpas can fulfill these needs for future leaders everywherewe utilized googles firebase htmlcss javascript and djs to build everything seen in this prototypewe struggled first to learn how to effectively utilize googles firebase api with the other technologies that we knew already additionally we struggled to narrow down exactly which parts of the project we felt we should prioritize building in this short time periodwere proud that we were able to build at least a prototype that demonstrates surpass vast potential to help leaders in all aspects of accountability which includes an authorization system built through firebase and a preliminary view of the automatically generated accountability reportseach member of our team learned something newwhether it was tackling web dev for the first time or checking out all the functionalities for googles firebase whats next for surpaswe will continue to develop the prototype until it more closely resembles our final product then look more deeply at how to bring our mainly webbased application to the mobile space
housemate as housemates for the past two years we drew inspiration from our experience of dealing with the daily tasks associated with living with others this includes the collection of household funds that go towards house supplies and the allocation of weekly chores we wanted to develop an ios app which would help with these functionsessentially the purpose of this app is to facilitate a quick easy and organized meeting between all household members it can assist in the brainstorming and prioritizing of a list of chores and creating a visual of the current total household fundsthe app was built with xcode and written in swift since this was new for all team members we struggled with saving the data of users into the app so in between launches the user input is not saved how ui works in xcodeswift how storyboards work and linking it to some very basic functions whats next for housemateimplementation of core data along with the additional functions of reminders scheduling events and connecting with fellow housemates
mentalx connect seems like a fairly simple game on paper but playing it without a board is a completely different story trying to hold the patterns of the board in your head while simultaneously trying to win the game and prevent your opponent from winning as well is taxing yet strangely addictive mentalx is a boardless customizable connect variant it can be customized for different sizes different amounts needed to be connected and soon will have player and axes implementation it currently allows peers to play with each other on the same laptop and also has an ai functionality where a monte carlo tree search learning artificial intelligence seeks to beat any challenger first we created the connect game with a small command line user interface and then added on different variations such as not showing the board until one player got four of a kind and changing the size after this was finished we researched different game playing methods for ai and discovered the monte carlo tree search algorithm we implemented this and have the ai using this method to choose its moves whats next for mentalxmentalxs primary platform is not computers creating aesthetic user interfaces and increased computer functionality would be nice but the future for mentalx lies in the mobile industry using bluetooth to connect with friends creating a time mode where players only have seconds to make a move or even doing pass and play functionality all are fundamentally easier on mobile devices we also plan on including an advanced mode where one has to know which move they make that wins the game for them or they lose mentalxs technology can be extended to other games such as hex in an effort to increase pattern recognition and endurance
bitcard we wanted to do something involving bitcoin and chrome extension and came across this ideaallows you to shop online on a site that doesnt traditionally accept bitcoin when you make a purchase it sends the bitcoin to our coinbase account and we issue you a prepaid capital one nessie credit card that you can use to make your purchase no annoying minute confirmationswe have a nodejs backend on heroku running the api integrations we use the coinbase and nessie apis to handle the money and deliver the app via a chrome extension firebase stores a hashmap between nessie customer ids and coinbase customer ids api integration issues implementing oauthnodejs integrations pratical application simple and eleganthow to use these apis make a chrome extensionwhats next for bitcarduse of other cryptocurrencies integration with other online wallet providers
errorcode its almost a fact developers dont like writing test cases sure it is a great feeling writing a test case and seeing all of your code pass but the actual act of writing out the test cases can be cumbersome and distracting this is where errorcode comes inerrorcode is a platform for developers to contractout their testing developers from around the world compete to write test cases that break your code yet follow the specs that you set fortherrorcode works by running a nodejs backend which serves a frontend that uses angularjs the application also uses firebase for the storage of project and test files that developers publish finally we use python and in the future other languages to run the project scripts and teststhe main challenges we faced was the development of the compilation engine and the act of coordinating file transfer between developer and backend it was quite a challenge having our nodejs server execute commands to download the python files and run them against the test fileswe are proud of our work in that it is a great foundation as a more robust code review tool there are many future features that we would like to implement and the platform provides great incentives for developers to participatewhats next for errorcodewe would like to build a more robust compilation engine which includes support for multiple languages we would also like to provide direct integration with services like github travisci circleci etc for easeofuse regarding the code download process finally our biggest area of improvement would be the development of the smart specification api use natural language processing and big data we would like to use the data from specifications on our site to predict test cases and test suite partitions for a given piece of code these recommendations would be invaluable to the user with the possible development of a test suite generator purely from specifications
leaplock leaplock was inspired by the gesture based locking mechanism on android phones and the hassle of having to deal with physical keys leaplock allows users to use d hand gestures to unlock a safe or any kind of lock users can register hand gestures as a password gesture the lock then only opens when the user inputs the same hand gesture againwe used the leapmotion controller to track hand gestures nodejs with socketio for the web interface and beaker for additional pattern visualizations whats next for leaplockleaplock is applicable to a variety of systems and devices that need authentication for example when youre traveling you can use it to unlock luggage or hotel room doors without having to deal with losing keys path vizualization with beaker notebook httpspubbeakernotebookcompublicationsafafdceabeae
emres our team wanted to create something motorized that could provide relief to those who undergo a health care emergency in real timethrough the emres app one can simply press a distress button and a car will come to their location with basic healthcare supplies in the mean time the car also sends the patients location to first responders in order to provide for a more immediate relief to their situationwe built this using intels processor as well as seeedstudios motorized car hardware we used java to program the car and ios for the appat first only member of our team knew how to code leading to some difficulties in the making processwe learned much about both the software and hardware aspectswhats next for emreswith investment and more time this can be used in first responder vehicles as well as on campuses to provide more immediate relief to health care emergencies
gaze deep learning as a tool can have a huge impact in the media industry with visual and audio content taking over of the internet people often struggle with navigating through unorganized media content our goal is to transform cluttered video content into a simplified and streamlined navigating experiencegaze organizes unorganized videos to help the user interpret and navigate visual information it allows the user to search video content by specific inputted text queries search educational lectures by locating timestamps for corresponding lecture slides search audio content and subtitles by specific inputted text querieshow we built itfirst we split the video into smaller scenes by creating an average brightness histogram and calculating entropy scenes were distinguished and determined by substantially different histogram and entropy results once scenes were separated we sent two frames from each scene to microsofts cognitive services to get a highly contextual description of the scene iterating through each description and clustering keywords into a giant bucket we were able to provide the users a platform to navigate through a media content with accuracy and easewe were limited to a lowend cpu from azure so video processing time took around ms per frame with around frames per clip whats next for gazelots of sleep and tourism
pereoscope httpsxkcdcomthis is an attempt at building a d live stream with a large ipdwe used the periscope apis to grab live video streams from two mobile devices then stitched those frames together to send to a vr viewing device the recording devices are attached to a dual selfie stickbasically everything about this was challengingtaping two capital one selfie sticks togetherstereoscopic vision is hardwhats next for pereoscope
kinvest we wanted to leverage machine learning to help lenders to kiva learn where their money could make the greatest impact kiva is an international nonprofit founded in and based in san francisco that works with microfinance institutions on five continents to provide loans to people without access to traditional banking systems lenders invest money in small businesses and fundraisers in underprivileged parts of the worldour goal was to quantify the impact of peoples donation and show people how even tiny amounts of money can help multiple families across the globe start businesses that are self sustainable kinvest is trained on kivas large datasets we used these to train a predictive model that can score the value of a dollar amount in a certain country and accurately predict the number of families that are directly impacted by a donors donation this encourages people to donate morekinvest is built in python we used data and machine learning libraries like pandas and sklearn we also integrated flask beaker notebook and firebasewith the data we had it was very difficult to define what a successful loan was or who a successful lender was it was also difficult to learn how to leverage all of our large tech stack in just hoursthe potential impact of kinvest is huge we are excited to see where kinvest will impact those in needfinishing our hack in hoursgoing from unfamiliar with these technologies to being able to properly implement them into an application was no small featthe satisfaction of hacking for goodhow to work with a large dataset in a limited amount of timethe importance of picking up languages and technologies on the flywhats next for kinvestwe want to study kivas dataset more deeply so that we can better predict what a good choice for a loan is the possibilities for linking up with other datasets world bank census economic data is nearly limitless we want to see where the societal impact of kinvest can go
postmates generosity we were thinking of interesting ways to use postmates and one thing that we thought was nice was to be able to donate through this app this webapps allows you to select a price value of a donation it will then optimize to find a meal that will fit the range and deliver it to the closest shelter in the users zone
dronar dronar was inspired by a love of cool technology drones are hot right now and the question is why not combine it with vr the result is an awesome product that allows for drone management to be more visually intuitive letting users interact with drones in ways never done beforedronar allows users to view realtime information about their drones such as positional data and status using this information users can make on the spot decisions of how to interact with their drownunity vuforia for ar node socketio express azure for backendc is beautifulwhats next for dronaradding slam in order to make it easier to interact with the ar items
invn frustrated by having to look through multiple stores when trying to find a specific item last minute just moved into your new house and cant wait to order a new pillow from amazon hopefully we can solve these problems for youjust search for any item at invn specific such as quench blue plastic water bottle or nonspecific such as ceramic kitchen knife and well highlight the nearest stores nearby that currently stock that item you can click once to reserve it and pick it up at your own convenience or click to order and get it delivered asap by postmatesbackend database and custom api is built using django in python and uses the google maps api for geolocation data were simulating the postmates api for the delivery mockup and then basic web tech for the front endteam work distribution becomes a problem when trying to ideate quickly and work at speedwhats next for invnwe wish to continue fleshing out the product until a truly useful mvp exists at which point well be requesting further feedback from potential users before continuing further
termibox we spend half our time in the browser and half our time on terminal because were nerds so we decided to merge themtermibox brings the functionality of the terminal into the web and then somewe implemented different bash commands ls cd grep as they would apply to websites for instance typing cd will bring you back to your previous page and cd will bring you to your home pagebut then we added some new functionality as well we created our own commands like datasetgen to easily search the web using our extension typing datasetgen will manually create a downloadable database of relevant pictures based on the querywe added in a new chrome extension by using omnibox thats triggered by typing into the url bar then for each command we commonly used in terminal we tried to think about how it would apply to the internet some like cd were easy to transition others like grep or cat required some creativity the next step in our project was to implement something in termibox that was harder in terminal this brought us to datasetgen its often difficult to find good datasets so we used the bing search api to search for any query passed into datasetgen and added capability to easily download these datasets some of the apis were rather difficult to use and it took us a really long time to get images of a decent quality by filtering out logos etc through our web scraperwe implemented a whole bunch of terminal commands and managed to have enough time to integrate some new commands we also built a website which serves as the termibox manual also we managed to hide a pusheen in our extensionfind it if you canwe learned how to develop chrome extensionswhats next for termiboxwell make the github repos public so people can add whatever new commands they would want to see
snapahotel the complications of travelsnapahotel uses android wear to find nearby hotels with a simple snap an individual can find the nearest hotel roomswe utilized the amadeus api and androidstudio to develop the appextracting the right data from amadeus to fit on the watch was a challenge and getting the gestures on the watch to work was a challengeim proud that we were able to learn so much from a simple idea and have an idea for a unique appi learned that using gestures and api data is very particular and can lead to a lot of errorssnapahotel is a start to easier travel adding onto the application will allow users to find nearby activities taxis and other useful travel items with simple hand gestures
textura many computer vision programs will tell you if a specific predefined and pretrained feature is present in an image textura is a lightweight program that will train online for the feature you requestyou input an image and an adjective works best with textures or easily identifiable visual patterns and we give you a matching scoreflask for the web app theano for the cnnstheano debugging is quite difficult a working product and something that id work on even after the end of the hackathontheano debugging experience basic image processing in python to actually normalize images to input into the cnnswhats next for texturabetter accuracy faster interface smoother experience
oshen id really like to be socialmedia famous but i dont want to put in the time and effort to get there what if i could use an algorithm to suggest content id be able to generate tweets that are popular with my followers who can spread my words of wisdom and attract new followerstwitter data is read into a mongodb instance from there a series of asynchronous and parallelized data processes form intermediate representations and eventually build out data that can be used to create tweetsi built a flask web app that handles the api that is exposed to consumers of the data from there i built a job queue service that handles requests for data asynchronously and in parallel this includes special handlers for making api requeststhe process of debugging jobs running asynchronously was the biggest hurdle to meeting my project timeline i was able to develop a process where i could make each step repeatable but in the end i couldnt totally solve more complex operations where id need to track two different jobs simultaneouslybuilding a successful data pipeline that has the potential to handle far larger quantities of data at this point im limited by the rate at which i can get data out of twitter instead of the compute time or disk readwritestart simple and make data changes repeatable theres no need to build in more complex options into a system ahead of future perceived slowdowns when the code doesnt run the important bits yetwhats next for oshenmore complex analytics id like to move into sentiment analysis and deeper analysis of the best time of day for my tweet engagement as well as a scraping utility that looks for new web content that matches suggested material
worth watching we all like movies but we hate spending time and money watching horrible movies that have been overly hyped up we built an intelligent tool to help predict whether upcoming movies are worth watching we are using imdb metacritic and rotten tomatoes to determine the quality of the movies and twitter to find out how the community really feels about it to come up with an accurate result
orrery the inspiration for this app was to create an app that overlays star data and constellations in virtual reality in order to create a unique user experienceusing the camera it detects star informationthe backend uses java and opencv for star detection from camera we wrote an algorithm from scratch and used machine learning to train the data in order to detect star information from images of stars the frontend is an android appinitially we tried using encog library for machine learning and used ec instances to train our data but because we were writing the machine learning part without using a machine learning api and training it ourselves we kept running out of ram and had limited system resources initially we wanted to display the constellation star data on the hololens but we could not figure out unity in time as it took a long time to install along with visual studiothe backend to detect star data was completed relatively quicklywe learned a lot about using new technologiessuch as hololens whats next for orrerymore resources to train machine learning algorithm
emojiworld emojiworldemojiworld uses the oculus gearvr headset to submit the users to an augmented reality where faces in their surroundings are analyzed and replaced with the emoji that best matches their current expression
xkcdd it is often easy to find oneself engrossed in the vastness of the internet it was our duty to society to provide each and every man woman and child the opportunity for laughter and joy amongst their daily browsing activities hence xkcdd was bornborn from the desire to bring intelligent comedy when least expected to deliver maximum enjoyment xkcdd automatically curates an xkcd post based on what you are currently searching in chrome whether on google or bing as a bonus feature a interactive visual gallery of presidential xkcd mosaics and information about each of them is presented in honor of the upcoming election season nicknamed merica modexkcdd is a chrome extension thus it was developed primarily using javascript additionally the data crunching tasks related to the mosaic creation process was performed using pythons image manipulation capabilities the majority of the development team had no experience developing chrome extensions thus the related technologies had to be learned in order to successfully complete this project additionally this project was not started until multiple hours into hackmit due to technical difficulties with the hardware the team was planning on using for their original idea finally the team had limited animation experience which made the added presidential xkcd mosaic show a challenge we have successfully created an application that works as we intended it to it provides satisfaction to not only our team members but all who we have demonstrated xkcdd to we believe that this application will provide joy to many users in the future never give up we started late switched projects a few times and had never developed a chrome extension before yet our team was able to successful deliver a polished final project that will benefit a plethora of userswhats next for xkcddfeature enhancement stability improvement increased relevancy of the posts that are displayed to the user and added functionality
window share window shareintuitive content sharing simply drag a program window from one computer to anotherseamless local sharingwindow share is the most intuitive way for you to share the things you enjoy with those close to you help your coworkers on their projects use multiple computers for optimum efficiency or get through the wee hours of the morning at your next hackathondrag and dropall you need to do is move your mouse off the side of your screen and it controls the computer next to you if youre grabbing a window itll send whatever file is open in that window along for the ride and if they dont have the program you have the file open in it will open in their defaultcrossplatformyes if you drag a notepad file onto your friends mac itll open textedit its a new way to pass notes in class
hillarytrump the app was inspired by the th degrees of kevin bacon game we wanted to make a light hearted project that is easy to showcase and gives information about the us presidential election candidateits a website where you can enter a wordtopic and then it will show you a link path from the wikipedia article for the word you gave to the articles for the candidatesit will also show you how many times the articles for both candidates have been viewed on wikipedia the past daysfinally it will look up all the news articles relating to the candidates from the past few days look at how many times your search term was mentioned in those articles and it reports that number as wellthe frontend was built on top of a templatethe backend was written in python and was made into a web service using flaskfor the wikipedia links we scrape the wikipedia articles for links and then run a simple greedy algorithm with a heuristic on the results to find pathsfor the page views we use the eventregistry apifor the articles we also use the eventregistry api and then parse the result using beautiful soupthe backend and frontend are hosted on separate heroku nodesutwe originally tried to deploy both our frontend and backend on the same node which we didnt get to work properly getting the run time of our wikipedia crawler algorithm down to reasonable speedsactually managing to come up with an ideabuilding a web webcrawler from scratchhow to use flask and the eventregistry apihow to build a web crawlerwhats next for hillarytrumpmake our algorithms faster add in new data to report and add support for the candidates from past elections
game of drones ever wish you could order food from the comfort of your car game of drones provides advanced route planning algorithms for drones to deliver food to moving vehicles using real time openstreetmaps data and postmates fee estimatesgame of drones also provides an enterpriseside drone control and management tool drones once dispatched can be tracked by customers in realtime on the same app customers are shown street view feeds from the gps coordinates of the drone
logo lens we hope this app encourages users to invest in the stocks and grow their personal investmentswhen the user sees a logo in everyday life and wants to learn more about the financial performance of said company in the stock exchange the user can simply perform the airtap gesture and the hololens will take a snapshot of the current view then the image is sent to googles cloud vision api and analyzed to see if there are any logos in the picture if a logo is detected the company of the logo is found and the nasdaq api is used to determine the recent performance of the companys stock finally this financial data is visualized on the hololens through unity we had the hololens take a picture after receiving an airtap gesture the picture is then run through a chain of apis specifically google vision to detect logos a company name csv to get ticker names from company names and nasdaq api to check stock priceswe had challenges in implementing a gesture to capture photos capturing photos sending a json request through unity to the cloud vision api parsing xml from the nasdaq api and scripting in unity because the hololens hasnt been developed on much yet there was little documentation and examples to learn from becoming familiarized with developing for an ar environment using unity and the windows holographic platform figuring out the cloud vision image recognition api to detect images from the snapshot the user takes on the hololensarmixed reality is an emerging field and devices like the hololens have incredible potential it was a great learning experience to work with the hololens and figure out how to use unity whats next for logo lens by incorporating capital one api we could simulate buying and selling stocks on the go selecting what pieces of data are more helpful to the user and presenting them using clean and easy to understand visualizations
tangotator we wanted to explore the possibilities of augmented realitycurrently not muchunity stuffunity is surprisingly hard to use for a bunch of codersparts of it work and are coolgame dev is a completely different paradigmwhats next for tangotatoradd the planned functionality for multiple users
hackmit stock price prediction we have an interest in neural networks and have heard of recurrent neural networks being used for stock price prediction we then thought that we could try to augment past market data used to train stock prediction rnns with sentiment data on those stocksit forecasts stock prices using a time series of stock data thats labelled with sentiments on those stocks at a given time pointwe built our neural network using keras and visualized data outputed from our model on a nodejs webappquite a few ranging from setting up our nodejs server obtaining sentiment data training our neural net quite a range of things mainly pertaining to using dataused datafor our stock prices we used hourly nasdaq market data for facebook and apple for our sentiment data we used sentiment data on theses stocks gathered and kindly provided by late on a saturday night pierce crosby of stocktwits
bitinvoice bitcoin has enormous potential to change the financial ecosystem of the world as someone with a passion for this technology i hoped to develop an application around it at hackmitbitinvoice offers the user a template for a basic invoice in addition to basic details that one may find on an invoice template this template generator is hooked up to the coinbase api to generate a new bitcoin address for each invoice created each one of these individual addresses belongs to the coinbase wallet that the user owns any small business owner with a coinbase account would have the ability to generate infinite invoices for their customers that would be quick and free of hassle for both parties bitinvoice is a web application that was developed in python on the flask web framework for the bitcoin part of the project i used the coinbase api i used a number of python libraries for things like qr code generation and pdf generationhaving not had much experience working with apis this project was certainly challenging in this regard though i did learn a lot from ithaving a working application was immensely satisfying especially so because it is a bitcoin application that serves a valuable purposei developed my abilities in programming with python throughout this project specifically i became a lot more comfortable with the flask web framework and gained a better understanding for apiswhats next for bitinvoicebitinvoice has a lot of potential capabilities the next step is implementing an automated billing system in which the recipient of the invoice has a certain amount of time to pay their bill before automatic contract termination there are also many other exciting opportunities for how to integrate bitcoin into the world of international businesstobusiness commerce bitinvoice is only a start
cena post create a twitterlike social network without a central dbit uses a bittorrentlike algorithm to create a distributed hash table dht with users posts and other information we used python and built nearly everything from scratch lack of wifi limited time difficult conceptsunderstanding the data structures involved in making this projecthow bittorrent protocol works theory behind distributed hashtables principles of networkswhats next for cena postadding more functionality like username searches encryption and improved efficiency
askthecandidates with the debates coming up we wanted to come up with a way of involving everyone we all have topics that we want to hear the candidates discuss most of all and we realised that we could use markov chains to do itenter a topic and watch as we generate a conversation between hillary clinton and donald trump on the subjectwe use a library of speeches from both candidates and markov chains to generate responsesit was important to ensure coherency where possible that was difficult since politicians are evasive at the best of timesour wonderful front end and the unintentional hilarity of the candidates responses
picky pusheen no one wants to go around asking for people to hang out with them with little to no knowledge of what they need to do or how free they are picky pusheen eliminates a lot of needless conversations and rejectionswe advertise your need to do a certain activity getting dinner jogging getting groceries and your friends can browse through their friends activities including yours and pair up depending on their preferences also we have the functionality to schedule an activity with just the press of a button further streamlining the processnativescript allowed us to easily build a crossplatform mobile app with just a bit of javascript the backend is built with rails and our remote button is an arduino powered by the photon wifi dev kitvery poor internet speed crippled us for the first hours of this hackathon so we didnt get nearly as much done as we wouldn have likedcreating a hack that uses both hardware and software in a nontrivial mannernativescript and general mobile developmentwhats next for picky pusheenit will be the vehicle we use to have a lot less awkward conversations and hang out a lot more during everyday tasks
hand roller i was inspired by the sheer size and amount of peoplethings happening at hackmit since i had never been to a college hackathon before i didnt want to miss out on any of the action but i also obviously could not be more than one place at once so i thought why dont i just make a robot that i can control wirelessly to take my phone and scope out the events i thought it would also be fun to use the leap motion to communicate with the robot so it would be a no touch remote control which was what i implementedthe robot moves according to certain gestures that the leap motion tracks if you hold your hand flat the robot goes forward index finger extended only makes it turn left and pinky finger extended only makes it turn right when you make a fist the robot stopsi used the hercules robotics kit from intel as well as the inteledison and arduino extended boards these acted as a parallel computer to my own allowing cross platform communication the intel edison is connected to my computer through wifi the leap motion pushes data that it processes through my computer and the leap motion api onto a static localhost server run through flask the inteledison cpu unit then sends continuous get requests to this server downloading the output strings and using those as commands for its motor functionsfirst off there were several different very specific manuals for building the hercules but no comprehensive one so i just figured out all the wiring and connections on my own as someone with very little background experience in electronic circuits this was a difficulty i did not anticipate as i thought the manual would guide me through it my second challenge was that i thought that the inteledison already communicated with the computer hence why it was originally guided by keypresses however since the inteledison is its own computer the keyboard merely acted as a wirelessly connected keyboard instead of the edison actually retrieving data from the computer i did not realize there was no communication between the platforms so setting up a static server as a proxy proved to be the most difficult part of the code by fari am proud that i actually was able to have hack that was very heavy in both hardware and software components since i usually tend to focus on only one or the other additionally i had never set up a static server and used ajax for postget requests before so im glad that the datatransfer actually worked outi learned how to use flask to set up a static server how to use ajaxjson for data inputoutput requests and how to effectively wire an electronics systemwhats next for hand rolleralthough the leap motion api is a good start it is not a very extensive api and therefore does not have the best hand mapping functions built in next time i hope to create a wrapper class and define my own gestures in order to have more accurate tracking for the remote control
render a research matchmaking app we wanted to create an application to help enhance some portion of our college experience we realized that many of us were interested in research on campus and sometimes had trouble finding the exact professor or grad student that had projects that fit our specific interests with render a student or professor can log in fill out a form of their information and then be match with multiple others who share similar interests in a way it is a matchmaking app similar to tinder and bumble whats next for render a research matchmaking appa more streamlined navigation systeman interactiveresponsive websitelocation based featuresthe ability for people to match outside of ones college
motion control sensor our team really wanted to learn how to use some of the cool hardware availablethe device detects motion and alerts users using a piezoelectric buzzerwe connected a buzzer and motion sensor to a raspberry pi using a breadboard the device is controlled by a laptop running python that was connected by an ethernet cablethere were no jumper cables so we had to innovate a way to connect the wires to the raspberry pi also none of us had any experience using raspberry pi so it was challenging to learnwe started to learn how to use a new device raspberry pi that we were not previously familiar withit takes a lot of components and patience to learn how to use a new devicewhats next for motion control sensorlearn how to adapt raspberry pi to take in audio inputs
breast cancer detection to develop a fast and efficient way of detecting biomarkers for diagnosis of breast cancer in women our program has a set of images of cells undergoing mitotic divisions which are good biomarkers for prognosis of breast cancer we take in the image of the breast tissue break the image down to the size in which we have the standard atypia cell images and then compare for any presence of abnormality in the breast cells collecting images of mitotic cells and using wolfram alphas machine learning algorithm searching for criteria for a cell to be cancerous comparing the atypia cells to breast cells learning things in short time coming up with algorithms for biomaker detection targeting a real world complex problem machine learning using wolfram alphas development platformwhats next for detection of breast cancer based on image analysis coming up with an exhaustive set of criteria for cancerous breast cells taking into account the orientation of the cells and convolutions making it into a user friendly software
etsy keyworder i was inspired by my own etsy shop kangaroocraftsetsycom i found the process of scanning through hundreds of popular product listings to find keywords and crosschecking them using the etsy search engine and google adwords to be tedious so i thought maybe an app can do thisideally this app pulls data from the etsy api specifically collecting keywords from trending categories and the associated trending tags these recommended keywords are then stored in the application the user inputs simple words that may describe their new listing the app concatenates all logical twoword combinations of keywords and cross checks these simple words and concatenations with the recommended keywords list and returns a list of highly searched words that the seller should use in their own listing title and tagscurrently the webapp is broken i have a barebones user interface built using html include that going into this i only had basic python skills i had to learn about apis and web hosting then i learned html i am in the process of writing the working code using javascript jquery and node include the fact that i learned so many options for developing whats next for etsykeyworder i hope it actually works so i never have to do grueling seo by hand again i also plan to integrate it with google adwords to optimize listings in google search i know from experience that the trends on google are definitely different than the trends on etsy so it is important to note the distinction this app is currently specific to the etsy communitys trends and the etsy search engine
ivy we were inspired by this httpsyoutubecqbkhygdzmivy is a virtual assistant you can see as a d hologram you can talk to her as though she is a real person and she will interact with you you can ask her about information such as weather stocks flight information and sports scores she can even tell you jokes as an added bonus she can send the data you ask her right to your phone so you are always notified ivy is powered by ibm watson to handle conversations and artificial intelligence we taught her a bunch of things and she picked it up using machine learning the web app was built using nodejs emberjs html and css we also used the twilio api to handle mobile notifications ivy was hosted and deployed using bluemix the actual hologram is displayed using a clear prism that we built placed atop a screen running the web app ibm watson does a terrible job mixing plain javascript with nodejs and this caused a lot of problems for us as relatively simple problems took incredibly complex solutions building a hologram that works looks cool and is powered by artificial intelligence we learned that javascript is a really messy but powerful language we also got the chance to build a practical artificial intelligencewhats next for ivywe want to make ivy into a complete virtual assistant we want to make it so that a user can text ivy for questions and she will respond to answers just like she would when you talk to her similar to a text based chat bot but even more practical we want to push our artificial intelligence platform paired with the hologram technology to make ivy an actual assistant that can be used in public spaces for example a holographic librarian just like in the video above that a visitor can walk up to and ask questions we feel as though this technology has a lot of potential in the real world we just need to scale up very exciting stuff
mojichat in our digital age its hard to gauge a genuine reaction to communication we send with mojichat intended to seek a solution to that problem using the preferred alphabet of our generationemojimojichat lets you send your friends captioned photos and get their facial response in the form of an emoji when a friend sends you a photo on mojichat it takes a photo of your face and determines the emotion of it and sends one of eight animated emoji back each corresponding to an emotionmojichats core technology is microsoft cognitive services emotion api which can determine emotion from photos the app itself is built entirely in swift and runs on a firebase backendwe originally intended to run mojichat on a parse analog and had some trouble learning the ins and outs of firebase as with any unfamiliar technology it felt as though we were swimming upstream some of the time which when we were especially glad to have firebase mentors on site to help us outwe developed a unique alphabet of emoji specifically for the app all of which were fully animated by our team graphic designer julian we also had a very clear vision from the start and worked to follow through on the app we wanted to create at hackmit finally we worked as a team to create a clear and understandable user interface for the appbackends as a service take time to learn they arent always just plug and play and of course software development always takes twice as long as you expect it towhats next for mojichatthe four of us learned a lot about what we can and cannot do developing this app and will definitely be taking it to our projects in the future whether they be on ios the web or a gessoed canvas
f the mit mailing list freefood is frequently contacted by members of the community offering free food students rush to the location of free food only to find its been claimed from the firsthand accounts of other students as well as personal experience we know that its incredibly hard to respond fast enough to free food when notified by the mailing list f collects information about free food from the freefood mailing list the location of the food is parsed from the emails and then using the phones gps and the whereismitedu api the distance to the food is calculated using a combination of the distance and the age of the email the food listings are sortedthis app was built with android studio using java and a few different libraries and apisemails from freefoodmitedu are automatically forward to a gmail account that the app has access to using an android mail library we parsed the location in the form of various names nicknames to determine which building food is located at then the users location is taken to calculate the distance between the free food and the phones gps location the user receives a list of free food including the buildinglocation distance from their own coordinates and the age of the free food how long ago the email was sent at first we wrote the mail readingparsing code in vanilla java outside of android studio however when we tried to integrate it with the app we realized that java libraries arent necessarily compatible with android hence a considerable of time late at night was put toward reworking the mail code to be compatible with androidalso there were difficulties in retrieving gps coordinates especially with regard to accessing fine location permissions and various stability issues creating our first app none of us had prior android development experiencemaking horrible punshow to sortof use android studiohow emailimap workshow to use gitgithubhow to use regular expressionswhats next for fsettings for a search radiusrefresh periodically in backgroundpusheen notificationsmore pusheen
homebites university students often skip out on meals or pursue food only when its free for these students dinner has become an unavoidable expenditure instead of an enjoyable tasty experience with homebites students can conveniently experience the joys of a warmly cooked meals with interesting companyhomebites connects guests to local hostsresidents who are willing to make a homecooked meal in addition given the commitment of preparing meals homebites has a catering option for hosts who have extra food ensuring that hosts do not lose money whatsoever this is ideally suited for university students who want a homecooked meal as well as travelers who wish to taste authentic local food in a regionhomebites was built with microsoft azure nodejs facebook messenger and graph api postmates api and apiaiazures machine learning studio has problem reading azures documentdb source in addition communication between the messenger chatbot and the azure database often needs to be debugged the fact that facebook messengers payment method requires several days for facebook to be approved means we need to seek alternative payment approaches and neither capital one nor coinbase the available payment apis are mainstream enough to reach a wide audienceaccomplishments were proud ofthe chatbot has a good user interface and is extremely convenient to usewe became more familiar with the graph and messenger api in facebook and microsoft azurewhats next for homebiteshomebites is ready to launch as soon as scalability issues are addressed
dank we all know that one guy who keeps telling your group to watch x movieyou watch x movie and its absolute trash like you expectedthis happens over and over how can you low key ignore his inout without seeming rudemaintains internal state of who was championing the movie from the getgo and how the groups movie perception changed over time uses math and stuff to take this deltadank and use it to update each members valueasaperson which determines how much their input is weighted
vr dj we wanted to hack on the htc vive and learn a new technologyvr dj allows you to visualize and manipulate music you are placed in a world where you can see glowing bars that change size based on the frequencies of the music you can then change the volume by moving the controllers up and down change the tempo by moving the controllers closer and farther apart and move to the next song by moving one controller up and the other downwe used unity and the htc vive to develop our hack since neither of us had significant experience with unity and we had zero experience with vive we built it very slowly learning along the waywe had difficulty detecting input from the htc vive controllers and eventually chose to work around the issue due to time constraintswe made a thing our hack works and is usable and actually provides an interesting and somewhat humorous listening experiencelots we learned how to use unity c basic algebra and the vivewhats next for vr djlots be able to play any user selected song stored on their pcbe able to amplify only specific frequency bands similar to an equalizerallow track rewindingcolor changing visualization based on song tempo
pusheats pusheen psychology nativescript healthier living obesity is one of the leading causes of preventable death and we wanted to help address this growing crisiswe wrote an iosandroid mobile application based on psychologyneuroscience lab research dialogues that have been demonstrated to help people to improve their eating habits the application lets people record their meals enter mealtimes to get helpful nudges from pusheen and rate their mood before and after meals so that people can better understand the impact that their food choices are having on their life we also include random doses of xkcd comics related to food to encourage people to browse the app for funused heroku for flask app deployment for backendscraped xkcd pictures and tagged captions with monkeylearns machine classifier apis handtagged the categories that were relevant to healthy eating and generated listing of all xkcds suitable for healthy eating appnativescript to develop mobile apptelerik platform to deploy app for prototypingworking with mobile apps for the first timegetting nativescript dependencies and iosandroid emulators set up on various devicesno success with microsoft ocr api for reading text from xkcd comicsimages comicsansforcaptchaslosing a laptop for several hours due to windows autoupdateworking with nativescript and flask for the first timeworking together with a ml api to improve image tagging qualitydeploying our first mobile apphow to integrate different technologies to make a mobile app workwhats next for pusheatspitching the app to friends at the psych lab
splitpay every time we go out with friends its always a pain to figure payments for each person charging people through venmo is often tedious and requires lots of time what we wanted to do was to make the whole process either by just easily scanning a receipt and then being able to charge your friends immediatelyour app takes a picture of a receipt and sends to a python serverthat we made which filters and manipulates the image before performing ocr afterwards the ocr is parsed and the items and associated prices are sent to the main app where the user can then easily charge his friends for use of the servicewe built the frontend of the app using meteor to allow easy reactivity and fast browsing time meanwhile we optimized the graphics so that the website works great on mobile screens afterwards we send the photo data to a flask server where we run combination of python c and bash code to preprocess and then analyze the sent images specifically the following operations are performed for image processingrgb to binary thresholdingcanny edge detectionprobabilistic hough lines on canny imagecalculation of rotation disparity to warp imageerosion to act as a floodfill on letterswe ran into a lot of challenge actively getting the ocr from the receipts established libraries such microsoft showed poor performance as a result we ended up testing and creating our own methods for preprocessing and then analyzing the images of receipts we received we tried many different methods for different stepsdifferent thresholding methods some of which are documented belowdifferent deskewing algorithms including hough lines and bounding boxes to calculate skew angledifferent morphological operators to increase clarityrecognition of textsanother difficulty we ran into was implementing ui such that it would run smoothly on mobile deviceswere very proud of the robust parsing algorithm that we ended up creating to classify text from receiptsthe the building of splitpay we learned many different techniques in machine vision we also learned about implementing communication between two web frameworks and about the reactivity used to build meteorwhats next for splitpayin the future we hope to continue the development of splitpay and to make it easier to use with easier browsing of friends and more integration with other external apis such as ones from facebook microsoft uber etc
semantic zoom whats next for semantic zoomcoming soon
wireless controlled rover we got some inspiration from the intel booth and some ideas we came up on our ownits a robot that is controlled by the internet over wifi we use an android smartphone to send it commands from the users input touchspeech these commands are sent from phone to firebase and then the edison takes it off of firebase and talks to the arduino which then controls the motors to make it movewe initially started out with the seed studio wd base and then realized that we couldnt use the supplied board for our purposes we then decided to use the intel edison to talk to the motor controllers over ic after running into major issues with ic and the edison we decided to use an arduino to control then instead and then have the edison control the arduino over serial using the usb host functionality we programmed the arduino to take the letters l r f r for left right forward and reverse over serial we then programmed the intel edison to pull the command data from firebase and from there we pushed it with serialport to the arduino were controlling with an android smartphone with a custom built app the app has four buttons labeled left right forward and back to all the user to control the robot over wifi once any of these buttons are pressed the app sends the data to firebase and the edison is constantly listening so it then notifies the arduino of the command which then in turn talks to the motor controllers which then makes it movewe ran into a lot of problems with the seeed studio kit and the intel edison for some reason we couldnt get ic to work with the edison which is why we had to use an arduino to interface with the motor controllers if we were able to get ic working it wouldve been a much cleaner solution with less lag also the seeed studio kit had some odd instructions where we put two motors back to back and they both had hall effect sensors on the back with large magnets that prevented the two motors from turning individually also one of our team members had initally wired up the kit but didnt realize that he had made a mistake which took some time to figure out the aa battery pack was also a hassle for some reason where it wasnt making good contact with the batteries so it looked like everything was fine but the pack wasnt outputting voltage meaning that there was a break somewhere i even tested the continuity all around and it was fine strangely enough after a few times of removing the batteries and reinserting them it started to work againwere proud that it actually moves and workswe learned that sometimes the hardware may be faulty and its not your code intel edison ic problem also learned a lot about different apis and programs like nodejs and firebasewhats next for wireless controlled roverto hopefully make voice recognition seamless
additive recurrent neural net i was inspired by the ability of recurrent nets to learn cyclical patterns and i wanted something that could learn a cyclical pattern in a smooth space like a sin wave over continuous numbersfor each frame xi the net computes the output fxi and adds it to the state so that xi xi fxiby handit turned out theano didnt help the project at all because i was just doing an exploration and didnt need backpropogation therefore i ditched it and implemented a neural net by handgood proof of concept of cyclical behavior
conversationalist weve all been in a situation where some of the participants in a meeting or group project are dominating the discussion while others are rarely getting the chance to make their opinions heard oftentimes individuals do not realize how much they are talking relative to others in the group this issue is particularly relevant to underrepresented and minority groups who may have trouble speaking out in such settingsconversationalist aims to solve or at least increase awareness of this problem by combining microphone information from each participants smartphonelaptop in order to display a dynamic infographic that uses the brightness of each users name to highlight those who should be given an opportunity to contribute morenote in order for the js to access microphone data you will need to go to chromeflags and enable experimental web platform features
scrub oftentimes it takes quite a long time to find the right spot in longer videos even when we know exactly what we are looking for this is especially true with lectures and documentaries with recent developments in audio transcription we can now search many videos by their dialog contentscrub uses the captions generated and sometimes handwritten for youtube videos to allow users to query locations in videos where a certain word or phrase is spoken we are also looking into using the speech recognition capabilities of ios to allow us to transcribe personal videos as wellwe built both an ios mobile app and a react web app for this both utilizing an xmlbased api for youtube to receive generated captions for videos embeddable youtube players allow us to play the video at the given time stamp of a phrase when it happens for the ios personal video dialog search we are investigating using the mediaplayer and speech frameworks to locate and transcribe video filesunexpected issues with youtube players due to changes in ios as well as several issues involving parsing xml and launching herold to host the web app fairly smooth sailing otherwise thoughbeing able to quickly show all instances of a word or phrase in an hourlong lecture video within seconds in a clean ui for both ios and webtheres still a long way to go with speechtotext particularly in the face of noise accents and so forth additionally some youtube videos dont allow access to captioning via their api due to copyright issueswhats next for scrubgetting a working implementation of personal video transcriptions and further optimizing the transcription process hopefully developing an android version as well and a simpler chrome extension to allow users to use scrub while they are on youtube itself
money with friends i used to work at paypal and i sometimes give money to friends i like using the paypal app and venmo to send money to friends but there are issues especially when you spell an email incorrectly this can lead to permanently lost money on paypal i know that sending and receiving money digital currency is a huge multibillion dollar industry with a lot of opportunity this app is supposed to use the capital one api nessie and the facebook api to connect your friends and send money i used a swift single view application to create an application for ios i only wrote some of the main application views as i ran into challenges that i could not resolvefirst and foremost the biggest challenge was scope i decided to build the app alone as my original partner decided not to come and implementing the nessie and facebook apis was a little too bold after i built the framework for the app and going to a few talks i dived into the apis i have not done very much with services and http so trying to do it on my own was a bad idea essentially i was not able to implement any of the apis i had set out to implementsecond i stayed to the end of the introduction ceremony and did not get a table the bleacher seats are extremely uncomfortable im also not a fan of using my laptop on my actual lap third the internet was unusable for a few hours at the beginning of the hackathon i could use xcode offline but i had to try to view the apis on my phonefinally i was extremely tired we left at pm pm est and had a hour flight with a hour layover we got here at am est i didnt sleep for over hours at around pm i crashed i had not planned on needing a host or sleeping but ended up needing both i slept until about am and did not get much more done on the project im a beginner in swift development and xcode but the app looks decent for a beginner in my opinion scope is extremely important if i had focused on just nessie or just facebook i could have probably gotten more added sleep is also important if im invited back next year ill be sure to bring or make a team and get here friday nightwhats next for money with friendsi may continue later just to have the experience for now money with friends is cancelled
faceplate faceplatewhether we like it or not digital screens have become a large part of lives whether we are looking at cooking recipes facetiming parents or working out at a gym we almost always have screens next to us it could be a phone a television or an ipad but they all consist of screenshowever the inconvenience of constantly having to hold the screen is always a nagging problem that people face because of this we decided to build a face detector that will allow the screen or any object to rotate up to degree motion this way as long as the user mantles their item on the machine they will be able to have a solid view of the screen so whether theyre cooking and reading their recipes or working out at a gym theyll be able to have both their hands free to do what they are doing this way people could concentrate more on their task at hand rather than worry about being handicapped
augmented paper with the coming of the iot age we wanted to explore the addition of new experiences in our interactions with physical objects and facilitate crossovers from the digital to the physical world since paper is a ubiquitous tool in our day to day life we decided to try to push the boundaries of how we interact with papera user places any piece of paper with textimages on it on our clipboard and they can now work with the text on the paper as if it were hyperlinks our augmented paper allows users to physically touch keywords and instantly receive google search results the user first needs to take a picture of the paper being interacted with and place it on our enhanced clipboard and can then go about touching pieces of text to get more informationwe used ultrasonic sensors with an arduino to determine the location of the users finger we used the google cloud api to preprocess the paper contents in order to map the physical ultrasonic data with the digital vision data we use a standardized x inch token as a measure of scale of the contents of the paperso many challenges we initially tried to use a rfid tag but later figured that sonar works better we struggled with macwindows compatibility issues and also struggled a fair bit with the d location and detection of the finger on the paper because of the time constraint of hours we could not develop more use cases and had to resort to just onewe learned to work with the google cloud vision api and interface with hardware in python we learned that there is a lot of work that can be done to augment paper and similar physical objects that all of us interact with in the daily worldwhats next for augmented paperadd new applications to enhance the experience with paper further design more use cases for this kind of technology
rockband rockband
tourdemarsvr we wanted to give virtual reality a purpose while pushing its limits and making it a fun experience for the userour game immerses the user in the middle of an asteroid belt the user is accompanied by a gunner and the two players must work together to complete the course in as little time as possible player drives the spacecraft using a stationary bike with embedded sensors that provide realtime input to the vr engine player controls uses a wireless game controller to blow up asteroids and clear the way to the finishour entire system relies on a firebase server for interdevice communication our bike hardware uses a potentiometer and halleffect sensor running on an arduino to measure the turnstate and rpms of the bike this data is continuously streamed to the firebase server where it can be retrieved by the virtual reality engine player and player constantly exchange game state information over the firebase server to synchronize their virtual reality experiences with virtually no latencywe had the option to use unity for our d engine but instead we used the smokybay d engine which was developed from scratch by magnus johnson we chose to use magnus engine because it allowed us to more easily at support for firebase and additional hardwarewe spent a large amount of time trying to arrive at the correct configuration of hardware for our application in particular we spent many hours working with the particle photon before realizing that its high level of latency makes it unsuitable for real time applications we had no prior experience with firebase and spent a lot of time integrating it into our project but it ultimately turned out to be a very elegant solutionwe are most proud of the integration aspect of our project we had to incorporate many sensors iphones a firebase database and a game controller into a holistic virtual reality experience this was in many ways frustrating but ultimately very rewardingin retrospect it would have been very helpful to have a more complete understanding of the hardware available to us and its limitationswhats next for tourdemarsvradd more sensors and potentially integrating leap motion instead of hand held gaming pad
radar despite the incredible amount of effort that is being poured into advanced dmotion tracking by researchers and large scale companies today developers rarely touch this paradigm because most people dont have access to the third party systems built around dmotion tracking the thing is though that people usually carry around the basic components for this form of interaction with them every day through their laptop and smartphone cameras so we decided to build an api for web developers to begin to explore this new form of interaction where the client doesnt need to carry any extra weightradar tracks motion in d through a webrtc configuration between a standard smartphone camera and a laptop or computer webcam the smartphone is horizontally placed parallel to the end of a laptop with the frontfacing camera pointing upwards xy movement is tracked by the laptop webcam and z movement moving towards or away the laptop screen is tracked by the phone camera together any moving object can be tracked in dimensions all of this is done in browser and can be used to interact with various web applications such as simulations games and navigation
rexthor beta even though we have been in school for only one month we have already witnessed so many people stressing out about everything from their social life to academics to economic status this has led to deterioration of their academic grades as well as social life our inspiration came from this problem that we want to fix with our product and hopefully destress people so they have the calmness and focus they need to do well in all aspect of their lifeit utilises facial emotion recognition to sense what and how the user is feeling the given day and sets the mood of lighting music temperature tv shows etc accordinglyfor now our prototype can control lighting and music it also uses speech recognition to personalise for each user whether heshe wants to skip to another song or change the settings of a deviceair conditioner tv etc every user will be prompted for songs they like to listen to in each mood and based on the input it would create playlists the user can then play on shuffle or edit using speech all without moving from their positionwe utilised existing apis including microsoft cognitive sciences emotion api google speech api and spotify api in javascript and python we also have a hardware aspectlighting where we built a circuit with leds and resistors and connected it to a raspberry pi to control the lightingintegration of backend with hardwaresilently installing raspberry pi without a keyboard monitor or mousestarted a project we can work on in the futurelearned and implemented apiscreated a modern and minimal user interface from scratchhow to deal with a variety of apisworking in a teamproject managementraspberry pi software and hardwarewhats next for rexthor betawe plan on expanding using leap motion and oculus rift further personalising for each user by allowing them to make hand gestures to change any setting and then virtually be in an environment where they can destress and calm themselves or get excited whenever they want to we also plan on implementing a variety of settings within a room including temperature tv channelshow locks etc
hate yourself productivity through guilt people especially students often get distracted while trying to do work by websites like facebook reddit netflix etc we wanted to build something that negatively reinforces visiting those pageshate yourself limits the amount of time you can spend on certain websites and will send you demeaning messages if you stay on them for a while this causes severe guilt and will make users want to do their work in extreme cases electric shock may be employed to physically harm the userwe wrote hate yourself as a google chrome extension and used an arduino and a battery and a bunch of capacitors to deliver the shockgetting enough voltage to actually make the shock hurt also centering divsfiguring out how to center divs how to center divswhats next for hate yourself productivity through guiltmake the shock aspect work
pico we wanted to bring the fun experience of prisma to the immersive world of vrthe user explores google street view photospheres transformed by our app into the style of different artistswe have a distributed server architecture comprising of a nodejs server and a python server which hosts our trained torch models the two run on different aws instances and communicate with each other with the grpc library a latitude longitude request is sent to the nodejs server which saves a photosphere to amazon s and sends the link to the python server which processes the image in the style of the artist and sends back an s image link the nodejs server then sends the s image link to the vr app the photosphere images for vr are mb right now deep learning models are capable of dealing with images that are mb training and integrating a deep learning network into python decreasing the latency of the model in creating different styles which is difficult as it is an iterative optimization process
connec we know were not the only ones who are frustrated with career fairs they are unorganized crowded and an awful experience for all parties involved as technologies improve it seems that career fairs stay the same we sought to change that and modernize the career fairconnec is a web application that replaces traditional lines at a career fair with an automated queuing system students can electronically join the queues of companies theyre interested in up to at a time and track their positions in realtime when they are close to the front of a queue a reminder is textmessaged to them on the other end recruiters can make company queues for students to see and join during recruitment they are presented with a screen that tells them the students name and the length of the queue when they are done speaking with a student they manually update the queue with a simple click of a buttonthe user interface of the web app was designed using sketch that design was converted into frontend code using the bootstrap framework the backend utilized nodejs expressjs and mongodbas this was our teams first hackathon it was surprising how difficult it was to decide on an idea we also had to learn a bunch of frameworks on the spot as time ran low we had to say farewell to some features we wanted to implementwere so proud of the amount of effort we put in we didnt plan to stay up as late as we did however we all made sacrifices for the sake of the projectwe learned a multitude of frameworks like nodejs expressjs and mongodb we were familiarized with the frontendbackend relationship we learned the valuable consequences of working in a team of friendswhats next for connecwe want to add the additional features we had to cut out such as a countdown clock to the time that career fair starts we also want to introduce the webapp to the schools career center for possible use at a future career fair
bliglass we wanted to make hardware technology that allows people with visual disabilities to be able to feel as independent as anyone elseit can direct people with visual disabilities to their desired destination and allow them to know when to take a turn and if there is a person or object in front of them to avoid itwe built it using swift on the application side using the mapkit and bluetooth framework we build the hardware side with arduino c code and bluetooth module to communicate with mobilewe could not pair our bluetooth module initially and we also could not add sound commandswe made a portable prototype which we can start using to test whether it can help people with visual disabilitieswe learned a lot of hardware components and how to configure it properly with different parts such as ultrasonic sensors and servo motorswhats next for bliglasstesting the prototype with people
glass ticker the idea for glass ticker came after adam read a news article several years ago announcing that computers had outnumbered humans in quantity of stock market trades we wrote glass ticker to examine the other side of the stock market humans and in particular their susceptibility to news mediawe sought to determine the impact of a news article on a humans tendency to invest in that company our program computes a metric we call the consumer investment coefficient which is a value ranging from zero to one that represents the correlation that the news coverage of a company on a given day will influence casual investors or people that do not work exclusively in finance to invest in the company the program also computes several other useful metrics that relate to the medias influence over the marketwe used the nasdaq apis to feed live stock market data into our program we brainstormed outlined and implemented a novel algorithm using several uncommon data transformations we wrote the code in a variety of programming languages but the primary mechanisms are implemented in pythonvisualizing our own processes was a complex undertaking due to the programs great degree of abstraction from reality and the complexity of the algorithm we were of course also limited by the fallibility of our bodies as two of our team members fell ill at some point and were not able to make it through the night we built a totally original algorithm that really worksfinance is hardwhats next for glass tickerwe believe that glass ticker can be relatively easily validated by grouping nasdaqlisted companies by sector and verifying that consumer industries are more highly correlated than industrial sectors in accordance with our premise that news coverage plays a large role in influencing investor decisions
aria youtube recently demonetized a large pool of videos many of which were made by career content creators they cited advertiser friendliness as the reason and targeted videos tagged or flagged with unsavory topics this caused quite the stir in the youtube community with many feeling snubbed by highview content that earned piddling revenue we wanted to create a content creation platform where the creator would be rewarded not by the amount of money advertisers were willing to pay but by consumers engagement with the content we wanted a system that would gauge interest and appreciation for media without unduly burdening the user to that end we built aria a platform where emotional analysis of viewers through facial and voice processing measure engagement would appropriately allocate funds to video creators we developed a web application where we output a video and during the playback of said video we grab visual and auditory information we send this information back and process the visual information using microsofts cognitive service api for emotional analysis and the auditory information using microsofts speech processing and text analysis apis we store these in a documentdb for later retrieval when calculating costs we retrieve information from our database and combine these values together into a metric that measures the difference between content creator intent and perceived user emotion and achieve a metric for how well a video achieves its goal using this value we transfer an appropriate amount of funds from a central revenue bank account to content creator accounts using the capital one nessie apiwe did not anticipate the difficulty of processing audio data taking data in as input sampling correctly converting the file format and ultimately converting this into a concrete sentiment value were all more challenging than we anticipated for the bulk of the video presenting software we remained entirely loyal to microsofts services and integrated each in a meaningful way sometimes simple ideas have difficult implementations even when we broke down our project into discrete manageable chunks unforeseen difficulties and misunderstandings resulted in a lot of time spent tinkering with code given a short time period to construct our project such as a hackathon setting focus on essential components is paramount whats next for ariaour video system is in a very early stage of development many features that are common across platforms such as youtube vimeo etc such as recommendations are absent in our current iteration aria can be expanded to achieve these while still retaining its core goals
mind palace i learned about the loci method in psychology class and found it interesting and having great potentialthe app creates and takes one through a virtual mind palace where one can place visual representations of topics at familiar locations afterwards one can play a game to test ones familiarity with your subject of memorization we used android studio to build and program this app we often had issues with github when pushingpullingmerging in addition android programming was new to a few of our team members the app successfully combines the creation of a mind palace with an interactive test of the users progress in memorizationwe learned many new programming techniques as well as how to divide the programming tasks to maximize efficiency whats next for hackmitwe would like to extend the project to customize the mind palace for the users
crowd search this week a year old girl went missing outside oslo in norway her parents posted about it on facebook and it was quickly shared by thousands of people an immense amount of comments scattered around a large amount of facebook posts consisted of people trying to help by offering to hang up posters aid in the search and similar a facebook group was started and grew to over people within a day the girl was found and maybe a few of the contributions helpedthis is just one example and similar events probably play out in a large number of countries and communities around the world even though facebook is a really impressive tool for quickly sharing information like this across a huge network it falls short on the other end of letting people contribute to the search facebook groups are too linear and has few tools that aid in making this as streamlined as possible the idea is to create a platform that covers thiscrowd search is split into two main partsthe first part displays structured information about the case letting people quickly get a grasp of the situation at hand it makes good use of rich media and ux design and presents the data in an understandable waythe second part is geared around collaboration between volunteers it allows the moderators of the missing person search to post information updates and tasks that people can perform to contribute towardscrowd search makes heavy use of firebase and is because of this a completely frontend based application hosted on firebase hosting the application itself is built using react by using firebase our application syncs updates in realtime whether its comments new posts or something as a simple as a task list checkbox firebase also lets us easily define a series of permission rules to make sure that only authorized moderators and admins can change existing data and similar authentication is done using facebook through firebases authentication providerto make development as smooth as possible we make use of a series of utilitieswe compile our javascript files with babel which lets us use new ecmascript featureswe quality check our source code using eslint known as lintingwe use webpack to bundle all our js and sass files together into one bundle which can then be deployed to any static file host were using firebase hostingwhats next for crowd searchthe features presented here function as an mvp to showcase what the platform could be used for theres a lot of possibilities for extension with a few examples beinginteractive mapssituational timelinescontact information
blackbox were trying to get involved in the ai chatbot craze and pull together cool pieces of technology including google cloud for our backend microsoft cognitive services and facebook messenger api have a look message black box on facebook and find out so much python state machines ie mapping out the whole user flow and making it as seamless as possible and nlp training working nlp many api integrations including eventful and zapatowhats next for blackbox integration with google calendar and movement towards a more general interactive calendar application its an assistant that will actively engage with you to try and get your taskseventsother parts of your life managed this has a lot of potential but for the sake of the hackathon we thought wed try do it on a topic thats more fun and of course im sure quite a few us can benefit from its advice
teslas wrath the security of airgapped systems is generally taken for granted as airgapping removes the primary vectors for infiltration and exploitation it is also generally assumed that even an infiltrated airgapped system is still relatively safe as the infiltrator has no way to activate their payload on demandteslas wrath tw uses the incidental rf emissions produced by the gpio pins of the intel edison and other compute boards to transmit and receive payloads between airgapped systems or iot devicesin its current state tw is capable of sending a payload from an edison board to a listening system such as the rtlu sdr this payload is sent on the fm band at a frequency of approximately mhz and is decoded by the client currently no signal processing is performed analysis is done by considering peaks over db as binary and all lesser signals binary the ultimate goal of tw is to provide a full twoway channel between airgapped systems without any specialized radio or signal processing equipment in theory and in practice on the transmission end this is made possible by the effect of spurious emissions from a proximate transmitter on the receivertw currently uses a single intel edison chip and arduino breakout board as the transmitter as well as an sdr nooelec rtl as the receiver both leverage linux and open source programs rtlsdr gqrxour initial attempt focused on using an offtheshelf fm transmitter to activate a gpio pin on the edison this quickly proved infeasible as the fm transmitter was imprecise and had substantial distortion and feedback issues we switched to a dualband transceiver but experienced separate issues with power output and legal frequency limitations upon switching to the edison for the role of transmission we experienced problems with limited range and signal strength although these were worked around by means of an antennagetting the intel edison to transmit on the fm band with limited resources and without specialized hardwareinterfacing with the intel edison and its gpiosradio regulations and power characteristicsfrequency modulation techniques and signal mixinghow to break rf equipmentwhats next for teslaswrathtw will ultimately be capable of complete twoway transmission as mentioned above similarly we plan to experiment further with noise reduction and range extension we would also like to experiment with more diverse hardware including the raspberry pi and other embeddable boards extending this potential to consumeroriented hardware desktops tablets servers is also a natural conclusion for tw
sid jareds grandmother is a highschool librarian and she deals with issues surrounding student ids everyday for example students often forget their physical ids but carry their cell phones at essentially all times she encourages students to take photos of their ids to display on their phones but more often than not the barcodes arent able to be read by the scannerour cms interface is accessible by school administrators who can add student account containing the information necessary to identify them particularly their student id our mobile application calls an api which extracts this information displaying the students photo name school name and barcode id students can request to change their password and a form is submitted to their emails for handlingour mobile application is built natively in swift and ios using xcode our cms interface is built on a stack of flask nginx gunicorn and htmlcss the database driving both clients is mysql running on sqlscriptsmitedu and our flask server is hosted on an aws ec instance ensuring that our connections sqlscriptsmitedu did not overlap furthermore ensuring our database model matched our orm developing in swift far different from the comfortable swift and building for a target version also recently released kicking the centos box on our ec instance required a lot of domain knowledge with respect to the libraries and frameworks we needed to import to run a flask serverselfhosting on aws utilizing a free technology at mit building an efficient orm building a cms as opposed to directly interacting with the databasewhats next for sidadding more schools enhancing security redesigning the ui
latext when working on problem sets for mathematics or computer science classes weve all found its a lot easier to write and think on paper or a white board than it is to think in latex the most tedious part of completing these problems always ends up being typing up this inspiration into latex our project has two parts the first part takes an image of written equations then processes the image and splits the work into lines using flood fill our program finds individual characters then sends these characters to shapecatchercom to map the character to a variety of possible unicode characters then our program chooses the most likely match based on a combination of shapecatchers specific score and our prioritizing of common characters then our program utilizes the relative locations of the characters in the initial image to determine if certain numbers are subscript superscript andor fractions finally our program combines the unicode characters and the positional information to generate and email latex code to the user which can then be added to a latex document by the user the second part uses the synaptics large touch sensor to allow the user to draw and input equations into the program the time based drawing data is then sent to a server running a tool called seshat which was written as a phd project by a computer scientist a couple years ago which interprets single line equations into latex codethe first part of our program runs entirely in python we use a variety of algorithms to complete the tasks listed above for the second part we used python to interpret touch data from the synaptics large touch sensor and parse it into a format that seshat could interpret then we used a post request to send this to seshat so we could return the response as a latex equation one of the challenges we ran into was the fact that a lot of character recognition systems utilize time based data in addition to the picture because of this we had to either find a way to get time based data or find a character recognition that didnt need it shape catcher was our first approach our main difficulty with using shape catcher was the fact that it didnt have any sort of api so we had to manually figure out what post request to send to get back a response in addition we had to learn how to parse the html response with time based data we utilized the synaptics touchpad to draw equations then we could send this data to seshat server to find the equation the biggest challenges here were getting the touchpad data to be collected efficiently with a high frame rate getting the data into the right format and properly getting data back from the seshat server we were most proud of the fact that we were able to individually implement all of these algorithms for ocr on our own and get them to work together through a variety of files written by a variety of people we definitely struggled with having clear code with clear specs that people could read and understand to work together with for the second part of the project were most proud of the fact that we were able to properly work with the synaptics touch sense to the extent where we could get data and properly interpret and format it we learned about utilizing get and post requests also we learned a ton about image processing with all of our work with the original image also we learned a lot about using external sensors through our experiments with the synaptics touch sensor whats next for latextright now latext unfortunately cant hit a lot of specialized mathematical symbols and expressions like integrals and sums our goal is next to expand the scope of what latext can accomplish then our plan would be to incorporate both sides of our project into an ipad app the ipad gives us the interfaces both of a large touchscreen for drawing equations and a camera for taking static pictures of written equations
general election trends every member of our group is interested in data analysis whilst looking through the possible hacks that the companies were suggesting we happened upon the presidential election data analysis project our project analyzes data from previous presidential elections and uses it to both notice trends in previous elections and also to use it to predict future resultswe first scraped the data from wikipedia using a javascript program we then analyzed the data by converting it into a csv file and running a data analysis on it in c we also created a visual graphic to help better visualize the data in htmljavascript we had some trouble coming up with an idea in addition none of us had worked with csv files or extracted data from a website before so we had to take some time to learn that we managed to create a fully functional intensity election map in addition we learned the basics of data analysis to help us with this project in generalwe learned the basics of data analysis how to extract data from websites and how to read and write from csv files whats next for general election trendswe want to use this program to help predict future election results in the future we noticed a general trendline in the data and hope to use that and multiple other factors to try and predict the results in the general election
sound supervisor familiar with the volume mixer in windows it allows users to control the volumes of the individual applications currently running on a given computer it is a great feature of the os but can be a hassle to use when using fullscreen applications or when you have a lot of windows open sound supervisor gives the user control of the volume mixer in the real world with a small usb peripheral device users assign applications to knobs on the face of the physical device which enables them to control the volumes of individual applications in the real world instead of having to alttab out of your development environment to change the volume of your music you can now use sound supervisor to do it without missing a beat using an arduino and a c application we were able to implement this volume mixer in hardware on the arduino side the analog signal from each of the potentiometer is filtered for noise and then transmitted over a serial port to the computer when it arrives in the fromscratch built c application the data is parsed once the data is parsed the c application makes windows kernel calls in order to modify the volume for a specific process the windows kernel is very stratified and audio is handled very differently from windows xp to vista to and so on finding a way to control process volume across installations was very difficult but making it happen was very satisfying and will produce a pretty useful little device going from nothing to a fully formed hardware peripheral with a supporting desktop application in less than hours was really difficult the team got lucky in that we ran into no major development roadblocks and could start focusing on polish with some time to spare rtfm every time stack overflow is good for little things but there is some merit to reading the the source documentation whats next for sound supervisorsince it was built with devons components its bound for his desk and everyday use
xkcd for america given the upcoming presidential election we wanted there to be a fun way for people to determine which candidate aligned more with their interests if they were to throw away all their preconceived notions about each candidate we were interested in using natural language processing and we all love reading xkcd comics so we decided there was an interesting way we could integrate these two traditionally disparate tasks reading funny comics vs reading about presidential candidate election infoplatformsessentially we boiled it down to the very basics our users visit our site to find what appears to be a very simple quiz you flip through a series of xkcd comics and you either upvote it or downvote it to indicate whether you found it interestingfunny at the end we determine which candidate you have a closer affinity with and show you the collective data of all the people whove participatedwe curated the speeches of trump and clinton from their election campaigns as well as nearly all of trumps tweets from the last year from this text corpus we ran the latent dirichlet allocation lda algorithm in order to get a collection of topics trump topics and clinton topics these topics were then mapped to the most closely corresponding xkcd comicsfrom there we built a frontend interface where users could indicate their interest in each xkcd comic which we tracked the results of to display a diagnosis at the end regarding whether they displayed more interest in clinton topics vs trump topicsfinding good equal sources of datacleaning the data in a way that the lda algorithm could accept itmaking sense of the lda algorithms results tendency to give garbage topicsmaking the bar graph show up with data resultsit worksweve found a good deal of interested users originally we werent sure if people would like it whats next for xkcd for americawe definitely think theres a lot of fun to be had with the data we have and our platform collecting more user data to make better visualizations and possibly compare with how this measures up to their preconceived candidate preferencecomparing the frequency that candidates used of sat words in their speeches to determine whod be more likely to attend college in and more
spot finding and paying for parking sucks so we made it betterspot is a parking assist mobile web app that removes the hassle of finding and paying for parking spot allows a user to set where they are going and will show nearby parking spots as well as meter time limits and cost per hourwe built a flask app that we then deployed to heroku the app itself is based on an arduino sensor that would monitor a parking spot and transmit the status whether the spot is available or not to a web app spot had two very large challenges both with the hardware and software aspects of the systemin regard to hardware he sensor and circuit that spot use are very simple however pushing the data a sensor receives to a server is quite difficult the normal way to do this is with an arduino ethernet shield however none were available the workaround to this was using a simple python script that read from the arduino data port and pushed the data up to the serverworking with a map api was difficult and something none of us had experience with
mit poles the idea started with a group chat we had with around people in it the idea was to add many people to the group chat in order to get a general consensus on an issue or topic groupme allows certain messages to be liked and we would like the answer we agreed with the most essentially creating a poll we had a lot of fun with the group chat and were inspired to make a version accessible to the entire mit community at the moment we have a sign up page set up where a new user can enter some preliminary information including their kerberos a verification email will then be sent to kerberosmitedu verifying that the user is affiliated with mit and has an mit email address the verification email will contain a code should be entered on the site and allow the user to proceed to the sitethe homepage allows the user to choose to create a poll which will be posted on the site in order for a user to view the results of any poll they must have answered the poll themselveswe built the website using bootstrap we also created a locally hosted database with mysql that contains all of the account information question data and answer data the site is also locally hostedat first we tried hosting the site and the database on amazon web services but didnt want to pay any money we then eventually decided to move everything to a local host it was a challenge to figure out the best host for the site and the database and the overall structurewere very proud of our signup feature and the email verification system we set upwe also are proud of basically everything weve done since we came in with little to no knowledge of how to make a website from scratch we learned about what a database was and how to make one we learned how to send and retrieve information from that database a lot of us were using php for the first time we also learned how to set up a local server and the pros and cons of different servers we also learned how to use bootstrap and integrate all of our different components togetherwhats next for mit poleswe want to add new features such as a join group feature that allows user to make subgroups and vote on issues with sub communities choosing whether to remain anonymous or notwe have code to show but didnt have time to upload it all to a bitbucket repo
smartcart as college students we are inspired by necessity to start cooking as we began our lives independent people cooking became a passion for us and we soon realized that this application needed to be created this was through the repeated amount of failures of not having the proper food items ready to cooksmartcart is a cross platform application that is designed to connect the world of recipes online to your devices smartcart starts off with a chrome extension that saves web page ingredients of a recipe and adds all the items to a cart in the cart it is compared to walmarts api to estimate the total cost it would take to prepare the recipe smartcart can be divided into three essential parts the first part is the chrome extension that triggers the application to save a webpages recipe information on a server this is coded in javascript the server itself is written in python and scrapes the website information for ingredient details while connected to firebase api and walmart api for price information meanwhile the web application is coded in angularjseach recipe website is formatted very differently and scraping this is very difficultcreated a full stack application in a plethora of different languageshow to make a chrome extension work in python http requests whats next for smartcart
linerunner line runnerbackgroundactors have lines some actors have a lot of lines lines are hard to memorize it takes a lot of time and requires a lot of line iteration in order to properly recall what youre supposed to say and when youre supposed to say it reading through your script to find your cue line can work but youre also prone to allowing your peripheral vision to accidentally read your own line as well i knew that you tell yourself but you definitely did not for years actors have been solving this problem by making friends and coercing them to help them study lines in their free time friends will read your cue aloud and then read your line to check to make sure youre right since you never see the script you cant accidentally read your line and foul up your practice sessionnow with line runner actors dont need friendstldrline runner can run lines with any character in any scene so long as it has a script file to reference simply tell it who you want to be line runner will read aloud your cue line and wait for you to say your line if youre wrong line runner will chastise you as much or more than your friend would if youre right line runner will skip forward to your next cuegod modefor an added challenge try god mode three wrong lines in a row and the program will rm rf this should encourage you to remember your lines
smartpark finding parking in urban areas can be a nightmare our vision is cars that communicate to each other whenever they see an open spaceour system uses computer vision and infrared sensors to detect gaps large enough to fit a car it then uploads the location and timestamp to the cloud for other users to see any user can get directions to a detected open spaceno more endless circling around the block use the cloud to find parking right awaywe combined kinect sensors and camera with openxl vehicle interface and an android tablet a frontfacing camera would use google vision to detect a parking lot a kinect on the side of the car would activate its camera and infrared to detect an open parking space the location would be then uploaded to firebase for other clients to seenetworking between different hardware was a huge challenge that took hours to overcomeour computer vision algorithm can successfully detect an open space in a parking lotmost of us were new to android development as well as working with vehicle datawhats next for smartparkan extension of this project would be to aggregate enough data to provide the probability of finding parking on any streetnetwork effect is the greatest potential of this project deploying at scaleimproving the space detection algorithm for detecting street parking
stockify beaker allows seamless integration and analysis of data today several articles mention companies names and their recent developments this inspired us to work on a browser extension that generates automated stock reports at the click of a buttona user can highlight any company they want to research and get details about the stocks performance along with a bootstrapesque framework that allows for instant numerical and statistical analysis within the browser using beaker data may be analyzed in multiple languages including python r c and results can be exported and published to other platforms for collaborationhttpsyoutubewqpubo
sesame typing passwords is inefficient and easy to detect we came up with a solution that makes it practically impossible to notice the entered passwordwe used webgazerjs a library that uses webcam to track eye movements to create a more secure and intuitive password system the user draws a password on the screen similar to android pattern unlock with their eyes in place of a password string
book reading bot brb the book reading bot brb programmatically flips through physical books and using tts reads the pages aloud there are also options to download the pdf or audiobooki read an article on the spectator how some lowincome students cannot afford textbooks and actually spend time at the library manually scanning the books on their phones i realized this was a perfect opportunity for technology to help people and eliminate repetitive tasks all you do is click start on the web app and the software and hardware do the rest another use case is for young children who do not know how to read yet using brb they can read dr seuss alone as kids nowadays spend too much time on the television i hope this might lure kids back to children bookson a high level technical overview the web app bootstrap sends an image to a flask server which uses ocr and tts
classsense gruseome detailswhats next for classsense
tuber google maps is cool but it could be coolergives alternate modes of transport along with energy expended time spent and style pointslots of google apisweb formatting is hard and so is learning a new language javascript in hoursthe website runs without failing and actually does exactly what we told it to dojavascript is a beautiful and effective language also i learned exactly what an api is and how it can be used in personal projectswhats next for tubermultiple modes of transport for a given journey ranking travel modes by travel time or energy or style points etc prettying up the map
efficient asd detection using machine learning autism spectrum disorder is a disease that needs to be caught early on in order for the patient at risk to lead a normal or near normal life research shows that self reported surveys and questionnaires are effective in determining the risk of autism in children but such tests are expensive and time consumingthe programin its current state generates a random data set that models the list of questionnaire responses for a particular child it is then trained to determine which children are likely to develop autism using part of this data set randomly generated data was used because actual data requires the signing off of a private investigator associated with a university the program was built using python and makes extensive use of pandas numplot and sklearn in order to manipulate data and set up the machine learning algorithmorganizing the data efficiently required the use of arrays and a data frame both of which had different methods to splice and modify data figuring out the proper methods to analyze and process the data correctly required a lot of trial and errori was able to build something by the end of hackmit and managed to do something in a medically related fieldmachine learning can be used to solve many classes of problems and many machine learning problems can be made easier by combining feature values into a single vectorwhats next for efficient asd detection using machine learningsupport for user inputs can be easily added next they were not implemented in this version due to a lack of time using university resources in order to gain access to the medical datasets already available online would help to train the model better creating a user interface or possibly a web application would be useful to collect data
sentimessenger sentimessengerour app lets the user upload their facebook messenger data to a familiar looking site they can download easily from facebook as a giant html file then the user can see a colorful visualization of all of their conversations over time with a sentiment analysis you can find the source code here httpsgithubcombrandondshermansentimessengerto try it out you have at allow unsafe scripts to be ran in your browser
hyre career fairs are hectic when so many students try to talk to recruiters at once recruiters dont have time to scan everyones paper resume at the fair and it is even harder to remember their faces after they drop off their paper resume we decided to make an app that associates a students face to hisher resume using facial recognition software recruiters can look at a students resume quickly at a career fair and remember the students facehyre is a web application created to aid both students and recruiters in the job hiring process students use the app to upload their resumes and pictures recruiters use the app by taking a picture of a student at career fair and immediately obtaining hisher resume through facial recognition software recruiters can save students they like in the app if recruiters are considering students for hire hyre can not only be used at career fairs but also at networking eventshyre was built using django python html javascript and a sqlite database for the web application the facial recognition software api was obtained from kairos an open source human analytics platformstaying awake especially after promising ourselves no caffeine also implementing facial recognition reliably and integrating it into our appmaking a complete product that we can demo at career fairhow to use django and how to create web applications none of us had prior experiencewhats next for hyrewe can significantly improve our facial recognition algorithm by using a more wellknown api which would take longer to implement in addition the app could be much more interactive for students where students could view companies and save recruiters that they met so that the students dont forget recruiters names and faces this would also be a cool project for microsoft hololens since recruiters could pull up resumes as holograms
shrimply pibbles as hip hop lovers we wanted to automate the beat creation process to give artists exposure to a wider range of accompanimentsimply click the button and listen to the musical creation generated before your earswe built the music around a javascript midi library midijs all of the instruments notes and beats are randomly generated in real timewe struggled with using randomization while also making the end product appealingwhats next for shrimply pibbleswatch out for shrimply pibbles next mixtape dropping on soundcloud winter
hotspot we were inspired by the conversation we had with one of the kensho developers he told us about how he studies the correlation between seemingly random pairs of events and the stock marketthis led us to ask the same question but in a more physical sense we wondered what are the similarly random patterns for a person in his day to day travelsthe app serves two purposesone for the consumer and one for the business owner foremost the user can see which places or being actively visited based on other users activitiesthese are the hot spots furthermore the user can also look at each businesss most common successorwhere an average user will most likely go to nextin order to gain valuable suggestions on new points of entertainment or businesses from a business owner standpoint he can see the quantitative results of the net user population on the website in order to track the flow of his customers this will allow a business owner to change practices based on the tendencies of his customersthe app was built for ios in swift it regularly posts the users location to a node server that triggers mongodb queries also the app requests a general lay of the land when first starting up where it makes a get request to the node server to get points of interest nearby these nearby points are found through the google maps api all of the hotness data and closest neighbor suggestions on the app stem from this api get request finally the website uses other api endpoints to get basic data in order to plot an undirected graphthe implementation of getting data from google was somewhat sloppy this along with the fact that we needed to make a high volume of requests led to occasional max outs on the google maps api limit constructing the graph also proved to be quite challenging finally creating mock data was horribly tedious do to the close relationship between the dataan sql db would have worked much better ps this did not need async javascriptthe interface of the app looks very professional and clean and the concept seemed to legitimatewe learned that the typical mean stack or its other expressions may not always function the best for example a php mysql combination would fulfill the role much better however we were limited in the fact that our best ios dev is also our best php dev on a more specific note we learned that googles map api can only make requests at one time this highlights the important of designing smart algorithms that minimize http requestswhats next for hotspotwe would like to implement this on a large scale where the number of business is not limited we believe this will do the best job of answering our initial question of whether or not patterns exist for a person in his day to day travels because most people move farther than a small multiple block radius also some notion of machine learning could benefit the analysis of this data for the business owner substantially
fermata we have so little time to reflect how we use our time and it would be amazing to know with a simple click what percentage of our time is used studying or sleeping or studying knowing these metrics doesnt fix anything but it gives us perspective on how we each live our liveswe are implementing a simple web application that categorizes how your time is used based on your google calendar knowing what percentage of your time is spent where provides perspective to all those who toil endlessly with minimal time for reflectionangularjs nodejs html css herokufirst web app development was difficult to understand how all the components fit togetherunderstanding and touching the full stacknodejs angularjs and how all the different components interactwhats next for fermatamake the frontend really simple and userfriendly
arthritisense arthritisense is a novel doctorpatient interface system that tracks the entire therapy process from reminding patients to do their exercises through monitoring correct positioning and providing feedback to the doctor the database communicates with a python program that dictates what exercise the patient needs to perform and uses the leap motion vr device to detect if the patient is performing the specific exercises correctly our project aims to increase communication between patients and doctors and to make arthritis exercises more accessible as well as fun for the million people in the us that suffer from arthritis we hope to continue development to bring a product to the market
mitgo pokemon golike a digital scavenger hunt around mitnativescript zzzzzzzzwe had issues trying to find the right framework to develop in and had to debug android studio for the longest time and learn that app maker isnt wellsuited to the projectit workshow difficult app development can be and learning about a simple framework that can make it a lot easierwhats next for mitgofinalizing it so that it properly functions
streetpay our project is an android application that allows users to pay street vendorsperformers for their services each user is able to log into our app and scan the qr codeenter the username of the vendor they are interacting with and they will then be directed to a web address specific to the vendor where they will enter the amount of transaction we also made a web based application that allows the vendor to see when a transaction has gone through but this is separate from the user website so they do not share information this allows users to buytip vendors without having to use cash and broadens the client base for the vendorsperformers
driving companion ford presentation but its unfinished
selfie anywhere billions of selfies every year with everyone always trying to get the perfect one selfie anywhere allows you take one anywhere in the worldandroid opencv google street view apis python magicandroid opencv google street view apis python dark magicandroid opencv google street view apis python trying to look for magicwhats next for selfie anywherebedselfie and then better and improved everything fancier image processing nicer user interface better server interactions
bobapirates whats next for bobapirates
meshed worlds the original inspiration came from wanting to mix the real world with a virtual one a way in which you could interact with a virtually generated world and feel like you where there as a result we decided to scan real world environments and then generating virtual reality worlds based on them we used the kinect for windows to scan the environment and the gearvr for the d world generated the main challenges we ran into were lack of documentation along with confusing instructions on how to approach this project we started without any experience on any of these tools so any minute step was a huge landmark we are very proud that now we can scan and generate d environments we learned that we should have talked to sponsors about their technologies from earlier on that virtual d rendering its a huge skill set on its own and that this is not just an overnight hack the next step will be to begin automating the entire set up from scanning all the environment up until rendering of the world
 a popup app reminding you to rest your eyes every minutes by looking at something ft away for seconds dont go blind both windows and mac versions availablemade at hackmit contributors lordique fok jennifer lauv katherine youngthe jar file is the executable for windows make sure that you place the nircmd folder inside the windows folder of the repository in your program files directory
skycart drones are the future with more and more advancements in drone technology drones are becoming accessible by everyone we saw an untapped marketplace for those in need of quick reliable deliveries in large cities where a few blocks could take too long to traverse by allowing people to have a way to deliver packages across cities we enable many time sensitive deliveries to take place this extends from the common consumer to industries and hospitalswhats next for skycart
chewytime recently weve all started to notice a trend at restaurants when you get there one of the biggest challenges is what do we order and there are a few ways people try to tackle this ask for recommendations of foodtext their foodie friend for helpstart browsing yelp and reading reviews to try to grasp what is the best thing to orderhowever sometimes recommendations by other people dont necessarily fit our taste which can lead to a possibly less than ideal meal this is where we come in trying to create the optimal meal for peoplethe app serves to not only allow for better food recommendations for the diner but also give restaurants a means of more powerful data analysis from a very high level the app serves as a means for massive data aggregation that aides both restaurants and users alike from the consumer side the app allows users to find a given restaurant and the associated menu from here the back end will also provide recommendations based upon a heuristic naive bayes algorithm in terms of the tools we used we built an app with a flask framework frontend that is linked to a mysql database and mobile development was done in swift in order to aid our development we leveraged a variety of apis including locu menus yelp restaurants google search autocompletion and facebookgraphapi future development and social network connectivity in order to provide a reasonable proof of concept recommendation system that took into account the users preferences we utilized the yelpacademicdataset this led to some difficulties when dealing with the sparsely populated feature matrix and applying appropriate algorithms to achieve a reasonable result for us deciding on such a large project that included an extensive front and back end in the end the experience was challenging yet really rewarding for us some of the most valuable experience was learning to work as a team on such a large project from both the front and back end and this was truly our defining experience where were working with few hours of sleep on a large project it honestly came down to delegation and team work that allowed us to finishwhats next for chewytimefor us we still look forwards to continually improving and further developing the app and see where it takes us this would mean hashing out more of the restaurant side of the application and building deeper functionality by leveraging networks
amicable we all realized that we spend way to much time planning while on vacation instead of vacationingami creates a planner for what you should do while on vacation there is a simple userinput form where you can enter the things youd like to do and how badly youd like to do them ami takes this into account and will plan your day considering factors that you might not want to have to deal with like hours places are open and how long it takes to get from one place to anotherwe used twosigmas beaker notebook we used a html form for user input implementing googles api to determine the locations and hours of the places users said they wanted to go see then a java cell takes in information about the locations hours and user preference to determine an optimal scheduleone of the strengths of the beaker notebook is its ability to use a variety of programming languages in the same notebook however that was also one of its core weaknesses we initially had trouble getting the different programming languages we used to communicate with each other furthermore we also ran into difficulties designing an algorithm that uses both user preferences and parameters about the various locations to create an optimal schedule in the end we settled on a greedy algorithm to accomplish this task we were able to use the strengths of various different programming languages such as java for creating algorithms and python for handling the data from the google api to create a optimized productwe learned that using various languages together is a massive challenge whats next for amicablecreate a ui accept more more information about the locations such what times these locations are the least crowded and how other tourists rate these locationssee a demotry entering in some places youd like to visit edit the sample events in the java class to see how the scheduling algorithm works
limited movement vehicle control using the brain sensing headband to control the movement of robotthis controls the movement of robot from the electric signals generated with muse headbandwe assembled the robot from scratch used the data from the muse headband to get the brains electric signal and finally used android studio to create a app in order to properly handle the movement of different motors inside the robotit took almost hours to make the robot running and finally realized the edison was faulty also it was hard to translate the date retrieved from muse for the movement of robotour team managed to get the front rotation of all motors of the robot over the wireless networkto translate the data from muse headband to control robotwhats next for limited movement vehicle controlthe team is trying to reach the position where the robots movement will synchronize with heads movement
fleye shared wanderlust and a penchant for saving money aka being a studentinspires users to pursue traveling even when tied down to a limiting budget our product lets the user fleye by the seat of their pants the backend was built using expressjs a node framework the handlebars templating engine and the amadeus api the front end was built using google maps html css and javascriptwe had a difficult time getting the backend and front end talking to one another we also had issues on the user end balancing constraints with freedom while we wanted to give the user agency we also wanted to constrain the search for query purposes learning how to use node learning how to utilize the skill set of every team member having a good team makes everything betterwhats next for fleyedeploy the site on herokumulticity roundtrip optionsextra information like purchasing powerpossibly utilizing yapq to furhter inspire travel efficiency
colovr colovr is a virtual experience allowing users to modify their environment with colors and models its a relaxing low poly experience that is the first of its kind to bring an accessible d experience to the google cardboard platform its a great way to become a creative in d without dropping a ton of money on vr hardwarewe used google daydream and extended off of the demo scene to our liking we used unity and c to create the scene and do all the user interactions we did painting and dragging objects around the scene using a common graphics technique called ray tracing we colored the scene by changing the vertex color we also created a palatte that allowed you to change tools colors and insert meshes we hand modeled the low poly meshes in mayathe main challenge was finding a proper mechanism for coloring the geometry in the scene we first tried to paint the mesh face by face but we had no way of accessing the entire face from the way the unity mesh was set up we then looked into an asset that would help us paint directly on top of the texture but it ended up being too slow textures tend to render too slowly so we ended up doing it with a vertex shader that would interpolate between vertex colors allowing real time painting of meshes we implemented it so that we changed all the vertices that belong to a fragment of a face the vertex shader was the fastest way that we could render real time painting and emulate the painting of a triangulated face our second biggest challenge was using ray tracing to find the object we were interacting with we had to navigate the unity api and get acquainted with their physics raytracer and mesh colliders to properly implement all interaction with the cursor our third challenge was making use of the controller that google daydream supplied us with it was great and very sandboxed but we were almost limited in terms of functionality we had to find a way to be able to change all colors insert different meshes and interact with the objects with only two available buttonswere proud of the fact that we were able to get a clean working project that was exactly what we pictured people seemed to really enjoy the concept and interaction how to optimize for a certain platform in terms of ui geometry textures and interactionwhats next for colovrhats interactive collaborative space for multiple users we want to be able to host the scene and make it accessible to multiple users at once and store the state of the scene maybe even turn it into an infinite world where users can explore what past users have done and see the changes other users make in real time
autofinger many accidents happen due to distractions either by using phones or the cars infotainment systemsautofinger allows you to contol your cars infotaiment system using a fingerprint scanner each finger signals a different function want to lower the temperature use your left pinky want to raise the temperature use your right pinky want to blow the horn use your middle finger its as simple as thatautofinger works using the synaptics fingerprint scanner to scan you fingers using java algorithms to match your finger to previously learned fingers to identify its position ie index then it operate the function linked to that finger
ar election we are two mit students who wanted to experiment with new technologies create something cool and have fun at hackmit politics especially the upcoming presidential election has been one of the more popular topics of discussion among our friendswe picked several dates to examine how the clintons and trumps popularity changed in each state over timewe used microsoft hololens unity and cdespite having no previous experience working with any of these technologies we feel like we learned so much in less than hourswhats next for ar electionmore interactive features with more data
dronar dronar was inspired by a love of cool technology drones are hot right now and the question is why not combine it with vr the result is an awesome product that allows for drone management to be more visually intuitive letting users interact with drones in ways never done beforedronar is a an augmented reality drone package management system whether the payloads are amazon packages or sensitive medicines ensuring the quality and integrity of what is inside is important dronar makes quality assurance on valuable package deliveries easier to perform and more visually intuitive all one needs is a google cardboard and a smartphone app traditionally there has been no guarantee your package will arrive safely via a drone dronar provides a level of quality assurance by allowing users to monitor flight status in real timeunity vuforia for ar node socketio express azure for backendc is beautifulwhats next for dronaradding slam in order to make it easier to interact with the ar items
drones for humanity secondorder autonomy after a bit of research we found that immediately following a natural disaster the lack of aid is the cause of most of the casualties in many third world countries it takes as long as a few weeks for first responders to rescue many survivors many people in need of food water medicine and other aid supplies can unfortunately not survive for longer than hours for this we have created a poc drone that can work with a thousand others to search identify and deliver aid to survivorsthe drone is fully autonomous given a set of gps coordinates it will be able to deliver a package without human intervention we took this concept a step further our drone will search a predefined area immediately following a natural disaster while it is doing so it is looking for survivors using some type of machine vision implementation for the purpose of this project we are using a color sensor camera and a color tag as our delivery point once the target has been found a small medicinal package is released by means of an electromagnet the drone then sends over the cellular network the coordinates of the drop notifying ground crews of the presence of a survivor furthermore this also prevents multiple drones from delivering a package to the same location the server coordinates the delivery on the scale of hundreds or thousands of drones simultaneously searching the areathe flight control is provided by the ardupilot module the collision avoidance and color detection is handled by an arduino internet access and pipelining is provided by a raspberry pi and the server is an online database running python on google app engine the ground station control is using the mission planner and provides realtime updates about the location of the drone cargo condition temperature etc everything is built on a mm racer quad frame essentially the flight computer handles all of the lowlevel flight controls as well as the gps navigation the main workhorse of this drone is the arduino which integrates information from sonar sensors an object sensing camera as well as a gps to guide the flight computer around obstacles and to locate the color tag which is representative of a victim of a natural disaster the arduino also takes in information from the accelerometer to be able to compute its position with the help of a downward facing camera in gpscompromised areasweight and power management considering the fact that we had to use a small racer quad that only had a pound maximum payload we had to use as few and as light components as possible additionally the power regulators on the motor controllers were only capable of powering a few small electronics we had to combine multiple regulators to be able to power all of the equipmentperhaps coming up with an application of drones that could have a farreaching impact the ability to save hundred or thousands of lives and possibly assist in economic development of thirdworld countriessomething as small as a drone can really make a difference in the world even saving a single life is substantial for a pseudoselfaware machine and is truly a step forward for technologywhats next for secondorder autonomyrobustness testing and implementation of the machine vision system of course scaling up the platform so that it may be a viable solution in thirdworld countries considering a clear need for the technology this project could be taken further for practical use
clippd we can take a link to a youtube video and a certain set of words then produce a clipped version of the video with just those wordsused express framework with ibm watson apifinding an accurate translation api was a difficult tasklearned a lot about ibm watson api and video editing packageswhats next for clippdadd ability to cut from multiple youtube videos in a single request
mesh the technological capabilities of the hololens google cardboard and other armrvr devices along with a distinct lack of a virtual interface for the real world lead us to investigate how we could manipulate atoms with bits control physical objects through virtual interactionsthis project provides a link between the virtual and physical worlds by allowing you to interact with physical objects from the virtual space the hololens provides realtime mapping of the area and functions as the gateway allowing the user to interact with holograms and other virtual objects which are then sent to other devices which control real world events such as driving a robot we mesh atoms and bits allowing seamless interaction between mrvr and the real worldusing unity we made a hololens app to visibly merge the virtual and physical worlds allowing the user to see the bits overlayed on the atoms we then open a network socket between the hololens and an android device running a premade app for the robot in order to send commands which are generated from the users input in the app the programmable robot kits that were using is actually a prototype which hasnt been released there is no wifi api for it and the bluetooth is using a special protocol and the development edition of hololens isnt that open at this moment as well thus we have spent most of our time hr on the communication between these two devices and to overcome the difficulties of interfacing with the cellrobots we contacted one of the cellrobot developers and they created a simple api for us to use to send commands to the robot something it wasnt able to do before the gear we are using for the vr component does not natively stream requiring us to use c to mimic the google street view android applicationby reading through lots of open source codes and getting the supports from technical mentors we figured out a way to communicate between the robots and hololens first we deployed an app on a tablet as the user interface to control the physical robots second we wrote a script to enable hololens to send requests to the tablet through http protocol third the tablet receive and transport the requests to the physical robots giving it specific actionswe learned how to develop and deploy ar apps to the hololens platformwe learned about c and unity developmentgained experience with the cellrobot platformwe learned how to do networking on a hololens to communicate to an android appwhats next for meshintegrate hololens holograms into live streaming video from galaxy for vr interfaces like google cardboard for shared experiences between ar and vr users using a universal coordinate systemwhen ar and mixed reality technologies become more commonplace being able to interact and affect the physical world through the virtual will be very important we will add more sophisticated interactions with the cellrobots in terms of more finedgrade actions and adding support for voice recognition for tasks for the hololens
an xkcd interactive story a bunch of rocks from the admission puzzle to the prizes list hackmit has a lot of references to xkcd inspired by the quirky humor that comes from these awesome comics i wanted to create a video game that encapsulates this nature it is a video game created in inspiration from the xkcd comic a bunch of rocks i chose the comic a bunch of rocks because the themes explored in the comic are things that every student can relate to thus allowing a more immersed experience you use the arrow keys and space bar to playthe art was all hand drawn in gimp and the program was created completely from scratch in javawhats nextimprovement of game play and continuation of the story
sunrise ordinary objects a bed and a lamp working together to create a smoother wakeup experiencethe bed is actually equipped with a system tracking the users sleep patterns which are shared with the lamp to allow it to wake one up at the most appropriate timewe solderered an accelerometer to an arduino to get livefeedback of the motions of the user lying in the bed and set up a python program to analyze the sleep phases and send the results live to a userfriendly dashboardwe struggled at first to connect all layers together the arduino had to send live data over to the python running the analytic program and this one had to send its result to the htmljs website thereafter our program written in python took considerably more time since we had to choose how to structure the data to then be analyzedour team is very proud over the fact that we managed to dispatch the workload in an efficient way and that the final product is actually functionalwe learned that making a product with even a small variety of components can take much more time than is ordinarily available also we realized that the teamwork we had helped us significantly towards having a working prototype by the time limitwhats next for sunriseimproving the users experience through the dashboard more relevance and more predictiveness
smart mirror each one of us wastes precious time staring into a mirror every morning as we recite the monotonous routine of brushing our teeth its something were taught to do from the youngest age an activity as mindless as they come but it doesnt have to bewith smart mirror that time can be fully utilized as you prepare for your day by examining your todo list reading new emails checking weather and traffic and soaking in other important bytes of information such as current events and financial news with a large and highdefinition screen smart mirror can bring you the utility of a traditional mirror with the functionality and efficiency of a computer in front of our mirror youll have access to numerous useful widgets that will help you get the most out of your daywe built smart mirror as a web app programmed in html css and javascript we felt this was the best approach towards reaching an mvp because we were able to have relatively easy access to utilities of the device such as the camera and the resources of several apis on the webour greatest challenge was deciding what approach we wanted to take in building this with little experience in web development we had a lot to learn in a short amount of time although our hack doesnt incorporate all of the features we initially imagined we feel it does justice to our original visionthrough creating smart mirror we learned a great deal about web development and project management we hope to continue working on the project in the coming weeks and see what more learning experiences we can glean from this formative project coming up we would like to create more widgets that dig into and provide richer information to the user incorporate a higher quality camera to improve the functionality of the mirror itself and build out customization and preference features that will tailor smart mirror to the needs of our users
soundtrak countless high school presentations where changing slides affected the quality of lecture teachers will benefit from the freedom of mobility obtained through contactfree slide advancementssoundtrak advances slides using audio input via external hardwarewe used an arduino and multiple microphones to respond to clicks the two microphones means that the device is directional and that the audience can not trigger the controlsintegrating the gui with the arduino due to an error in the communication protocol this absorbed several hourswe have a working project and we got sleep last nightwe learned that communication between the different members of our team is crucial even when something seems obviouswhats next for soundtrakwe can improve audio reception with more time via an fft implementation which can increase the variety of signals we can additionally implement this over more platforms such as videos and webbrowsers
touchyfeely screen originally we wanted to create a physical crossplatform volume mixer to control levels of various processes while staying in full screen it ended up being far more challenging than that but the basics were still achieved the python file is executed and it interprets and parses certain commands based on gestures and user inputwith a lot of help from synaptics its based on a large touchscreen manufactured by them included was a single example program and very little documentation it was a challenge to make this device just starting out it was hard to configure and install the drivers correctly just to interact with the board itself and beyond that very little documentation was available essentially we were handed the board and sent on our ways however synaptics provided a lot of mentoring and help whenever i needed it while pretty basic and not super efficient im proud of the algorithm i made for detecting the motion of the finger and the design choices i made throughout the code very few values are hardcoded in an effort to create something that could be used laterwhats next for touchyfeely screenmore touching and feeling
js policy when web developers use a thirdparty ad or analytics script eg google analytics they are trusting that party with their users data unfortunately thirdparties sometimes turn out to be malicious or they could be compromised the new york times experienced this at one point requiring them to tweet attn nytimescom readers do not click popup box warning about a virus its an unauthorized ad we are working to eliminate other possible exploits could include scraping sensitive personal or financial information from a web page and sending it back to the maliciouscompromised thirdpartys serversin order to protect user data its important to keep thirdparties in check however its impractical and incomplete to review thirdparty scripts manually so js policy offers a way to enforce what these scripts can and cant access on a web pagejs policy is a javascript sandbox that isolates thirdparty scripts from the primary javascript runtime and gives the sandbox a limited view of the dom the actual content on the pagejs policy is implemented using a web worker inside a sandboxed iframe with dom reads mutations passing through a detailed policy written by the web developer using the productjavascript is designed for single threaded applications so it lacks many useful synchronization primitives i had to implement some of these primitives by repurposing a few brand newexperimental browser featuresim proud of how i was able to get a proofofconcept demo of this idea up and running in just hours especially given that this is my first time working with the lowerlevel guts of the javascript runtimei learned a lot about service workers and javascripts runtimewhats next for js policyi am hoping to continue to develop the project to support more nuanced policiesjs policy uses a new experimental browser feature called sharedarraybuffers so it only works in chromium prerelease chrome with special settings so unfortunately a public url demo wouldnt be of much use
smartnighter redbull microsoft band maximizes your productivityavoids you getting stuck at an unfamiliar country during a connection flight visualstudio learning c and how to work with the band the hard way using uppercase help messages for the mentor queue not sleeping not knowing c beforehand we learned and actually like c now we did this in a team of only people is better than and late is better than neverwhats next for smartnighter finishing the notifications and healthy living features getting images to load properly to the band
flight aid originally we wanted to think of various ways drone delivery could be used to solve problems and decided to create an app for emergency medicine delivery as there are certainly situations in which someone might not be able to make it to the hospital or pharmacy drones could deliver lifesaving products like insulin and inhalersbuilding upon that i dont think many people enjoy having to drive to cvs or walgreens to pick up a prescription medicine so the drones could be used for all sorts of pharmaceutical deliveries as wellthis is a userfacing web app that allows the user to pick a delivery location and follow the delivery through realtime tracking the app also provides an etathe app is built on cherrypy and the styling is done with htmlcssscssjs jquery in terms of apis we used mapbox to set and view location for tracking and ordering this app was built off of dronekits api and drone delivery example and we used dronekits drone simulator to test itwe really wanted to add sms notifications that would alert the user when the package had arrived but ran into issues implementing the twilio api without a server using only jquery as most solutions utilized php it was also our first time working with cherrypy so that was a challenging learning experience in terms of picking up a new frameworkim proud of figuring out how to calculate eta given coordinates learning a lot more python than id previously ever known and integrating nice styling with the bare bones website im also proud of the photoshopped pusheen backgroundi learned how to work with new apis since i hadnt had much prior experience using them i also learned more python in the context of web development and jquerywhats next for flight aidi really want to figure out how to add notifications so i can flesh out more features of the userfacing app i would in the future want to build a supplierfacing app that would give the supplier analytics and alarms based on the drones sensor data
